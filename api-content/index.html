{"posts":[{"title":"Java 设计模式--建造者（Builder）模式","content":"建造者模式是日常开发中比较常见的设计模式，它的主要作用就是讲复杂事务创建的过程抽象出来，该抽象的不同实现方式，创建出的对象也不同。 通俗地讲，创建一个对象一般都会有一个固定的步骤，这个固定的步骤我们把它抽象出来。 建造者模式分为两种： 经典建造者模式 变种建造者模式 经典建造者模式 UML类图 四个角色： Product -- 产品 Builder -- 抽象的步骤 ConcreteBuilder -- Builder具体的实现 Director -- 使用者 代码： public class Computer { /*CPU*/ private String CPU; /*内存*/ private String memory; /*硬盘*/ private String hardDisk; /*键盘*/ private String keyboard; /*鼠标*/ private String mouse; public String getCPU() { return CPU; } public void setCPU(String CPU) { this.CPU = CPU; } public String getMemory() { return memory; } public void setMemory(String memory) { this.memory = memory; } public String getHardDisk() { return hardDisk; } public void setHardDisk(String hardDisk) { this.hardDisk = hardDisk; } public String getKeyboard() { return keyboard; } public void setKeyboard(String keyboard) { this.keyboard = keyboard; } public String getMouse() { return mouse; } public void setMouse(String mouse) { this.mouse = mouse; } @Override public String toString() { return &quot;Computer{&quot; + &quot;CPU='&quot; + CPU + '\\'' + &quot;, memory='&quot; + memory + '\\'' + &quot;, hardDisk='&quot; + hardDisk + '\\'' + &quot;, keyboard='&quot; + keyboard + '\\'' + &quot;, mouse='&quot; + mouse + '\\'' + '}'; } } Builder 类: public interface ComputerConfigBuilder { void setCPU(); void setMemery(); void setHardDisk(); void setKeyboard(); void setMouse(); Computer getComputer(); } 具体实现： public class LowConfigBuilder implements ComputerConfigBuilder { private Computer mComputer; public LowConfigBuilder(){ this.mComputer = new Computer(); } @Override public void setCPU() { mComputer.setCPU(&quot;i5&quot;); } @Override public void setMemery() { mComputer.setMemory(&quot;8G&quot;); } @Override public void setHardDisk() { mComputer.setHardDisk(&quot;500G&quot;); } @Override public void setKeyboard() { mComputer.setKeyboard(&quot;薄膜键盘&quot;); } @Override public void setMouse() { mComputer.setMouse(&quot;有线鼠标&quot;); } @Override public Computer getComputer() { return mComputer; } } Director: public class Director { private ComputerConfigBuilder mBuilder; public void setBuilder(ComputerConfigBuilder builder){ this.mBuilder = builder; } public void createComputer(){ mBuilder.setCPU(); mBuilder.setMemery(); mBuilder.setHardDisk(); mBuilder.setKeyboard(); mBuilder.setMouse(); } public Computer getComputer(){ return mBuilder.getComputer(); } } Test: Director director = new Director();//创建装机人员 director.setBuilder(new LowConfigBuilder()); //告诉装机人员电脑配置，这里为低配版 director.createComputer(); //装机人员开始组装 Computer computer = director.getComputer(); //从装机人员获取组装好的电脑 System.out.print(&quot;电脑配置：&quot; + computer.toString()); //查看电脑配置 director.setBuilder(new HighConfigBuider()); director.createComputer(); Computer computer = director.getComputer(); System.out.print(&quot;电脑配置：&quot; + computer.toString()); 变种Builder模式 代码： public class Person { /*名字（必须）*/ private final String name; /*性别（必须）*/ private final String gender; /*年龄（非必须）*/ private final String age; /*鞋子（非必须）*/ private final String shoes; /*衣服（非必须）*/ private final String clothes; /*钱（非必须）*/ private final String money; /*房子（非必须）*/ private final String house; /*汽车（非必须）*/ private final String car; /*职业（非必须）*/ private final String career; private Person(Builder builder) { this.name = builder.name; this.gender = builder.gender; this.age = builder.age; this.shoes = builder.shoes; this.clothes = builder.clothes; this.money = builder.money; this.house = builder.house; this.car = builder.car; this.career = builder.career; } public static class Builder { private final String name; private final String gender; private String age; private String shoes; private String clothes; private String money; private String house; private String car; private String career; public Builder(String name,String gender) { this.name = name; this.gender = gender; } public Builder age(String age) { this.age = age; return this; } public Builder car(String car) { this.car = car; return this; } public Builder shoes(String shoes) { this.shoes = shoes; return this; } public Builder clothes(String clothes) { this.clothes = clothes; return this; } public Builder money(String money) { this.money = money; return this; } public Builder house(String house) { this.house = house; return this; } public Builder career(String career) { this.career = career; return this; } public Person build(){ return new Person(this); } } Test: Person person = new Person.Builder(&quot;张三&quot;,&quot;男&quot;) .age(&quot;12&quot;) .money(&quot;1000000&quot;) .car(&quot;宝马&quot;) .build(); ","link":"http://blog.801314.top/post/java-she-ji-mo-shi-jian-zao-zhe-buildermo-shi/"},{"title":"Java调用实现调用http请求的几种常见方式","content":"Java项目中调用第三方接口的几种方式： 通过JDK网络类 java.net.HttpURLConnection 通过common封装好的 HttpClient 通过Apache封装好的CloseableHttpClient 通过SpringBoot-RestTemplate 通过JDK网络类 java.net.HttpURLConnection 实现过程： Get： 1. 创建远程连接 2. 设置连接方式 3. 设置连接超时时间 4. 设置响应读取时间 5. 发起请求 6. 获取请求数据 7. 关闭连接 Post： 1. 创建远程连接 2. 设置连接方式 3. 设置连接超时时间 4. 设置响应读取时间 5. 当向远程服务器传送数据/写数据时，需设置为 true （setDoOutput） 6. 当向远程服务器读取数据时，设置为true， 该参数可有可无 （setDoInput） 7. 设置传入参数的格式：（setRequestProperty） 8. 设置鉴权信息：Authorization：（setRequestProperty） 9. 设置参数 10. 发起请求 11. 获取请求数据 12. 关闭连接 代码： package com.riemann.springbootdemo.util.common.httpConnectionUtil; import org.springframework.lang.Nullable; import java.io.*; import java.net.HttpURLConnection; import java.net.MalformedURLException; import java.net.URL; import java.net.URLConnection; /** * @author riemann * @date 2019/05/24 23:42 */ public class HttpURLConnectionUtil { /** * Http get请求 * @param httpUrl 连接 * @return 响应数据 */ public static String doGet(String httpUrl){ //链接 HttpURLConnection connection = null; InputStream is = null; BufferedReader br = null; StringBuffer result = new StringBuffer(); try { //创建连接 URL url = new URL(httpUrl); connection = (HttpURLConnection) url.openConnection(); //设置请求方式 connection.setRequestMethod(&quot;GET&quot;); //设置连接超时时间 connection.setReadTimeout(15000); //开始连接 connection.connect(); //获取响应数据 if (connection.getResponseCode() == 200) { //获取返回的数据 is = connection.getInputStream(); if (null != is) { br = new BufferedReader(new InputStreamReader(is, &quot;UTF-8&quot;)); String temp = null; while (null != (temp = br.readLine())) { result.append(temp); } } } } catch (IOException e) { e.printStackTrace(); } finally { if (null != br) { try { br.close(); } catch (IOException e) { e.printStackTrace(); } } if (null != is) { try { is.close(); } catch (IOException e) { e.printStackTrace(); } } //关闭远程连接 connection.disconnect(); } return result.toString(); } /** * Http post请求 * @param httpUrl 连接 * @param param 参数 * @return */ public static String doPost(String httpUrl, @Nullable String param) { StringBuffer result = new StringBuffer(); //连接 HttpURLConnection connection = null; OutputStream os = null; InputStream is = null; BufferedReader br = null; try { //创建连接对象 URL url = new URL(httpUrl); //创建连接 connection = (HttpURLConnection) url.openConnection(); //设置请求方法 connection.setRequestMethod(&quot;POST&quot;); //设置连接超时时间 connection.setConnectTimeout(15000); //设置读取超时时间 connection.setReadTimeout(15000); //DoOutput设置是否向httpUrlConnection输出，DoInput设置是否从httpUrlConnection读入，此外发送post请求必须设置这两个 //设置是否可读取 connection.setDoOutput(true); connection.setDoInput(true); //设置通用的请求属性 connection.setRequestProperty(&quot;accept&quot;, &quot;*/*&quot;); connection.setRequestProperty(&quot;connection&quot;, &quot;Keep-Alive&quot;); connection.setRequestProperty(&quot;user-agent&quot;, &quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)&quot;); connection.setRequestProperty(&quot;Content-Type&quot;, &quot;application/json;charset=utf-8&quot;); //拼装参数 if (null != param &amp;&amp; param.equals(&quot;&quot;)) { //设置参数 os = connection.getOutputStream(); //拼装参数 os.write(param.getBytes(&quot;UTF-8&quot;)); } //设置权限 //设置请求头等 //开启连接 connection.connect(); //读取响应 if (connection.getResponseCode() == 200) { is = connection.getInputStream(); if (null != is) { br = new BufferedReader(new InputStreamReader(is, &quot;GBK&quot;)); String temp = null; while (null != (temp = br.readLine())) { result.append(temp); result.append(&quot;\\r\\n&quot;); } } } } catch (MalformedURLException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { //关闭连接 if(br!=null){ try { br.close(); } catch (IOException e) { e.printStackTrace(); } } if(os!=null){ try { os.close(); } catch (IOException e) { e.printStackTrace(); } } if(is!=null){ try { is.close(); } catch (IOException e) { e.printStackTrace(); } } //关闭连接 connection.disconnect(); } return result.toString(); } public static void main(String[] args) { String message = doPost(&quot;https://tcc.taobao.com/cc/json/mobile_tel_segment.htm?tel=13026194071&quot;, &quot;&quot;); System.out.println(message); } } 通过apache common 封装好的 HttpClient 步骤： 1. 生成一个 HttpClient 对象并设置相应的参数 2. 生成一个GetMethod对象或PostMethod并设置响应的参数 3. 用HttpClient生成的对象来执行GetMethod生成的Get方法 4. 处理响应状态码 5. 若响应正常，处理Http响应内容 6. 释放连接 导入jar包： &lt;!--HttpClient--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-httpclient&lt;/groupId&gt; &lt;artifactId&gt;commons-httpclient&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--fastjson--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.32&lt;/version&gt; &lt;/dependency&gt; 代码实现： package com.riemann.springbootdemo.util.common.httpConnectionUtil; import com.alibaba.fastjson.JSONObject; import org.apache.commons.httpclient.*; import org.apache.commons.httpclient.methods.GetMethod; import org.apache.commons.httpclient.methods.PostMethod; import org.apache.commons.httpclient.params.HttpMethodParams; import java.io.IOException; /** * @author riemann * @date 2019/05/25 0:58 */ public class HttpClientUtil { /** * httpClient的get请求方式 * 使用GetMethod来访问一个URL对应的网页实现步骤： * 1.生成一个HttpClient对象并设置相应的参数； * 2.生成一个GetMethod对象并设置响应的参数； * 3.用HttpClient生成的对象来执行GetMethod生成的Get方法； * 4.处理响应状态码； * 5.若响应正常，处理HTTP响应内容； * 6.释放连接。 * @param url * @param charset * @return */ public static String doGet(String url, String charset) { //1.生成HttpClient对象并设置参数 HttpClient httpClient = new HttpClient(); //设置Http连接超时为5秒 httpClient.getHttpConnectionManager().getParams().setConnectionTimeout(5000); //2.生成GetMethod对象并设置参数 GetMethod getMethod = new GetMethod(url); //设置get请求超时为5秒 getMethod.getParams().setParameter(HttpMethodParams.SO_TIMEOUT, 5000); //设置请求重试处理，用的是默认的重试处理：请求三次 getMethod.getParams().setParameter(HttpMethodParams.RETRY_HANDLER, new DefaultHttpMethodRetryHandler()); String response = &quot;&quot;; //3.执行HTTP GET 请求 try { int statusCode = httpClient.executeMethod(getMethod); //4.判断访问的状态码 if (statusCode != HttpStatus.SC_OK) { System.err.println(&quot;请求出错：&quot; + getMethod.getStatusLine()); } //5.处理HTTP响应内容 //HTTP响应头部信息，这里简单打印 Header[] headers = getMethod.getResponseHeaders(); for(Header h : headers) { System.out.println(h.getName() + &quot;---------------&quot; + h.getValue()); } //读取HTTP响应内容，这里简单打印网页内容 //读取为字节数组 byte[] responseBody = getMethod.getResponseBody(); response = new String(responseBody, charset); System.out.println(&quot;-----------response:&quot; + response); //读取为InputStream，在网页内容数据量大时候推荐使用 //InputStream response = getMethod.getResponseBodyAsStream(); } catch (HttpException e) { //发生致命的异常，可能是协议不对或者返回的内容有问题 System.out.println(&quot;请检查输入的URL!&quot;); e.printStackTrace(); } catch (IOException e) { //发生网络异常 System.out.println(&quot;发生网络异常!&quot;); } finally { //6.释放连接 getMethod.releaseConnection(); } return response; } /** * post请求 * @param url * @param json * @return */ public static String doPost(String url, JSONObject json){ HttpClient httpClient = new HttpClient(); PostMethod postMethod = new PostMethod(url); postMethod.addRequestHeader(&quot;accept&quot;, &quot;*/*&quot;); postMethod.addRequestHeader(&quot;connection&quot;, &quot;Keep-Alive&quot;); //设置json格式传送 postMethod.addRequestHeader(&quot;Content-Type&quot;, &quot;application/json;charset=GBK&quot;); //必须设置下面这个Header postMethod.addRequestHeader(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot;); //添加请求参数 postMethod.addParameter(&quot;commentId&quot;, json.getString(&quot;commentId&quot;)); String res = &quot;&quot;; try { int code = httpClient.executeMethod(postMethod); if (code == 200){ res = postMethod.getResponseBodyAsString(); System.out.println(res); } } catch (IOException e) { e.printStackTrace(); } return res; } public static void main(String[] args) { System.out.println(doGet(&quot;http://tcc.taobao.com/cc/json/mobile_tel_segment.htm?tel=13026194071&quot;, &quot;GBK&quot;)); System.out.println(&quot;-----------分割线------------&quot;); System.out.println(&quot;-----------分割线------------&quot;); System.out.println(&quot;-----------分割线------------&quot;); JSONObject jsonObject = new JSONObject(); jsonObject.put(&quot;commentId&quot;, &quot;13026194071&quot;); System.out.println(doPost(&quot;http://tcc.taobao.com/cc/json/mobile_tel_segment.htm?tel=13026194071&quot;, jsonObject)); } } 通过Apache 封装好的 CloseableHttpClient CloseableHttpClient 是在 HttpClient 的基础上修改更新而来的。 &lt;!--CloseableHttpClient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--fastjson--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.32&lt;/version&gt; &lt;/dependency&gt; package com.riemann.springbootdemo.util.common.httpConnectionUtil; import com.alibaba.fastjson.JSONObject; import org.apache.http.HttpResponse; import org.apache.http.HttpStatus; import org.apache.http.client.methods.CloseableHttpResponse; import org.apache.http.client.methods.HttpGet; import org.apache.http.client.methods.HttpPost; import org.apache.http.entity.StringEntity; import org.apache.http.impl.client.CloseableHttpClient; import org.apache.http.impl.client.HttpClientBuilder; import org.apache.http.util.EntityUtils; import java.io.IOException; import java.io.UnsupportedEncodingException; /** * @author riemann * @date 2019/05/25 1:35 */ public class CloseableHttpClientUtil { private static String tokenString = &quot;&quot;; private static String AUTH_TOKEN_EXPIRED = &quot;AUTH_TOKEN_EXPIRED&quot;; private static CloseableHttpClient httpClient = null; /** * 以get方式调用第三方接口 * @param url * @param token * @return */ public static String doGet(String url, String token) { //创建HttpClient对象 CloseableHttpClient httpClient = HttpClientBuilder.create().build(); HttpGet httpGet = new HttpGet(url); if (null != tokenString &amp;&amp; !tokenString.equals(&quot;&quot;)) { tokenString = getToken(); } //api_gateway_auth_token自定义header头，用于token验证使用 httpGet.addHeader(&quot;api_gateway_auth_token&quot;,tokenString); httpGet.addHeader(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot;); try { HttpResponse response = httpClient.execute(httpGet); if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) { //返回json格式 String res = EntityUtils.toString(response.getEntity()); return res; } } catch (IOException e) { e.printStackTrace(); } return null; } /** * 以post方式调用第三方接口 * @param url * @param json * @return */ public static String doPost(String url, JSONObject json) { if (null == httpClient) { httpClient = HttpClientBuilder.create().build(); } HttpPost httpPost = new HttpPost(url); if (null != tokenString &amp;&amp; tokenString.equals(&quot;&quot;)) { tokenString = getToken(); } //api_gateway_auth_token自定义header头，用于token验证使用 httpPost.addHeader(&quot;api_gateway_auth_token&quot;, tokenString); httpPost.addHeader(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot;); try { StringEntity se = new StringEntity(json.toString()); se.setContentEncoding(&quot;UTF-8&quot;); //发送json数据需要设置contentType se.setContentType(&quot;application/x-www-form-urlencoded&quot;); //设置请求参数 httpPost.setEntity(se); HttpResponse response = httpClient.execute(httpPost); if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) { //返回json格式 String res = EntityUtils.toString(response.getEntity()); return res; } } catch (IOException e) { e.printStackTrace(); } finally { if (httpClient != null){ try { httpClient.close(); } catch (IOException e) { e.printStackTrace(); } } } return null; } /** * 获取第三方接口的token */ public static String getToken() { String token = &quot;&quot;; JSONObject object = new JSONObject(); object.put(&quot;appid&quot;, &quot;appid&quot;); object.put(&quot;secretkey&quot;, &quot;secretkey&quot;); if (null == httpClient) { httpClient = HttpClientBuilder.create().build(); } HttpPost httpPost = new HttpPost(&quot;http://localhost/login&quot;); httpPost.addHeader(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot;); try { StringEntity se = new StringEntity(object.toString()); se.setContentEncoding(&quot;UTF-8&quot;); //发送json数据需要设置contentType se.setContentType(&quot;application/x-www-form-urlencoded&quot;); //设置请求参数 httpPost.setEntity(se); HttpResponse response = httpClient.execute(httpPost); //这里可以把返回的结果按照自定义的返回数据结果，把string转换成自定义类 //ResultTokenBO result = JSONObject.parseObject(response, ResultTokenBO.class); //把response转为jsonObject JSONObject result = (JSONObject) JSONObject.parseObject(String.valueOf(response)); if (result.containsKey(&quot;token&quot;)) { token = result.getString(&quot;token&quot;); } } catch (IOException e) { e.printStackTrace(); } return token; } /** * 测试 */ public static void test(String telephone) { JSONObject object = new JSONObject(); object.put(&quot;telephone&quot;, telephone); //首先获取token tokenString = getToken(); String response = doPost(&quot;http://localhost/searchUrl&quot;, object); //如果返回的结果是list形式的，需要使用JSONObject.parseArray转换 //List&lt;Result&gt; list = JSONObject.parseArray(response, Result.class); System.out.println(response); } public static void main(String[] args) { test(&quot;12345678910&quot;); } } 通过SpringBoot-RestTemplate springBoot-RestTemplate 是上面三种方式的集大成者，代码编写更加简单，目前可以采用的调用第三方接口有： delete() 在特定的URL上对资源执行HTTP DELETE操作 exchange() 在URL上执行特定的HTTP方法，返回包含对象的ResponseEntity，这个对象是从响应体中映射得到的 execute() 在URL上执行特定的HTTP方法，返回一个从响应体映射得到的对象 getForEntity() 发送一个HTTP GET请求，返回的ResponseEntity包含了响应体所映射成的对象 getForObject() 发送一个HTTP GET请求，返回的请求体将映射为一个对象 postForEntity() POST 数据到一个URL，返回包含一个对象的ResponseEntity，这个对象是从响应体中映射得到的 postForObject() POST 数据到一个URL，返回根据响应体匹配形成的对象 headForHeaders() 发送HTTP HEAD请求，返回包含特定资源URL的HTTP头 optionsForAllow() 发送HTTP OPTIONS请求，返回对特定URL的Allow头信息 postForLocation() POST 数据到一个URL，返回新创建资源的URL put() PUT 资源到特定的URL &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!--CloseableHttpClient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring restTemplate--&gt; &lt;!-- @ConfigurationProperties annotation processing (metadata for IDEs) 生成spring-configuration-metadata.json类，需要引入此类--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 在启动类同包下创建RestTemplateConfig.java 类 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.http.client.ClientHttpRequestFactory; import org.springframework.http.client.SimpleClientHttpRequestFactory; import org.springframework.web.client.RestTemplate; /** * @author riemann * @date 2019/05/25 2:16 */ @Configuration public class RestTemplateConfig { @Bean public RestTemplate restTemplate(ClientHttpRequestFactory factory){ return new RestTemplate(factory); } @Bean public ClientHttpRequestFactory simpleClientHttpRequestFactory(){ SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory(); factory.setConnectTimeout(15000); factory.setReadTimeout(5000); return factory; } } 然后在Service类（RestTemplateToInterface）中注入使用 import com.alibaba.fastjson.JSONObject; import com.swordfall.model.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.*; import org.springframework.stereotype.Service; import org.springframework.web.client.RestTemplate; /** * @author riemann * @date 2019/05/25 2:20 */ @Service public class RestTemplateToInterface { @Autowired private RestTemplate restTemplate; /** * 以get方式请求第三方http接口 getForEntity * @param url * @return */ public User doGetWith1(String url){ ResponseEntity&lt;User&gt; responseEntity = restTemplate.getForEntity(url, User.class); User user = responseEntity.getBody(); return user; } /** * 以get方式请求第三方http接口 getForObject * 返回值返回的是响应体，省去了我们再去getBody() * @param url * @return */ public User doGetWith2(String url){ User user = restTemplate.getForObject(url, User.class); return user; } /** * 以post方式请求第三方http接口 postForEntity * @param url * @return */ public String doPostWith1(String url){ User user = new User(&quot;小白&quot;, 20); ResponseEntity&lt;String&gt; responseEntity = restTemplate.postForEntity(url, user, String.class); String body = responseEntity.getBody(); return body; } /** * 以post方式请求第三方http接口 postForEntity * @param url * @return */ public String doPostWith2(String url){ User user = new User(&quot;小白&quot;, 20); String body = restTemplate.postForObject(url, user, String.class); return body; } /** * exchange * @return */ public String doExchange(String url, Integer age, String name){ //header参数 HttpHeaders headers = new HttpHeaders(); String token = &quot;asdfaf2322&quot;; headers.add(&quot;authorization&quot;, token); headers.setContentType(MediaType.APPLICATION_JSON); //放入body中的json参数 JSONObject obj = new JSONObject(); obj.put(&quot;age&quot;, age); obj.put(&quot;name&quot;, name); //组装 HttpEntity&lt;JSONObject&gt; request = new HttpEntity&lt;&gt;(obj, headers); ResponseEntity&lt;String&gt; responseEntity = restTemplate.exchange(url, HttpMethod.POST, request, String.class); String body = responseEntity.getBody(); return body; } } ","link":"http://blog.801314.top/post/java-diao-yong-shi-xian-diao-yong-http-qing-qiu-de-ji-chong-chang-jian-fang-shi/"},{"title":"Java 写文件三种方法比较","content":"import java.io.File; import java.io.FileOutputStream; import java.io.*; public class FileTest { public static void main(String[] args) { FileOutputStream out = null; FileOutputStream outSTr = null; BufferedOutputStream Buff = null; FileWriter fw = null; int count = 1000;//写文件行数 try { //经过测试：FileOutputStream执行耗时:17，6，10 毫秒 out = new FileOutputStream(new File(&quot;C:\\\\Users\\\\lee\\\\Desktop\\\\add.txt&quot;)); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; count; i++) { out.write(&quot;测试java 文件操作\\r\\n&quot;.getBytes()); } out.close(); long end = System.currentTimeMillis(); System.out.println(&quot;FileOutputStream执行耗时:&quot; + (end - begin) + &quot; 毫秒&quot;); //经过测试：ufferedOutputStream执行耗时:1,1，1 毫秒 outSTr = new FileOutputStream(new File(&quot;C:\\\\Users\\\\lee\\\\Desktop\\\\add0.txt&quot;)); Buff = new BufferedOutputStream(outSTr); long begin0 = System.currentTimeMillis(); for (int i = 0; i &lt; count; i++) { Buff.write(&quot;测试java 文件操作\\r\\n&quot;.getBytes()); } Buff.flush(); Buff.close(); long end0 = System.currentTimeMillis(); System.out.println(&quot;BufferedOutputStream执行耗时:&quot; + (end0 - begin0) + &quot; 毫秒&quot;); //经过测试：FileWriter执行耗时:3,9，5 毫秒 fw = new FileWriter(&quot;C:\\\\Users\\\\lee\\\\Desktop\\\\add2.txt&quot;); long begin3 = System.currentTimeMillis(); for (int i = 0; i &lt; count; i++) { fw.write(&quot;测试java 文件操作\\r\\n&quot;); } fw.close(); long end3 = System.currentTimeMillis(); System.out.println(&quot;FileWriter执行耗时:&quot; + (end3 - begin3) + &quot; 毫秒&quot;); } catch (Exception e) { e.printStackTrace(); } finally { try { fw.close(); Buff.close(); outSTr.close(); out.close(); } catch (Exception e) { e.printStackTrace(); } } } } ","link":"http://blog.801314.top/post/java-xie-wen-jian-san-chong-fang-fa-bi-jiao/"},{"title":"Java 读取文件完整版","content":"public class ReadFromFile { /** * 以字节为单位读取文件，常用于读二进制文件，如图片、声音、影像等文件。 */ public static void readFileByBytes(String fileName) { File file = new File(fileName); InputStream in = null; try { System.out.println(&quot;以字节为单位读取文件内容，一次读一个字节：&quot;); // 一次读一个字节 in = new FileInputStream(file); int tempbyte; while ((tempbyte = in.read()) != -1) { System.out.write(tempbyte); } in.close(); } catch (IOException e) { e.printStackTrace(); return; } try { System.out.println(&quot;以字节为单位读取文件内容，一次读多个字节：&quot;); // 一次读多个字节 byte[] tempbytes = new byte[100]; int byteread = 0; in = new FileInputStream(fileName); ReadFromFile.showAvailableBytes(in); // 读入多个字节到字节数组中，byteread为一次读入的字节数 while ((byteread = in.read(tempbytes)) != -1) { System.out.write(tempbytes, 0, byteread); } } catch (Exception e1) { e1.printStackTrace(); } finally { if (in != null) { try { in.close(); } catch (IOException e1) { } } } } /** * 以字符为单位读取文件，常用于读文本，数字等类型的文件 */ public static void readFileByChars(String fileName) { File file = new File(fileName); Reader reader = null; try { System.out.println(&quot;以字符为单位读取文件内容，一次读一个字节：&quot;); // 一次读一个字符 reader = new InputStreamReader(new FileInputStream(file)); int tempchar; while ((tempchar = reader.read()) != -1) { // 对于windows下，\\r\\n这两个字符在一起时，表示一个换行。 // 但如果这两个字符分开显示时，会换两次行。 // 因此，屏蔽掉\\r，或者屏蔽\\n。否则，将会多出很多空行。 if (((char) tempchar) != '\\r') { System.out.print((char) tempchar); } } reader.close(); } catch (Exception e) { e.printStackTrace(); } try { System.out.println(&quot;以字符为单位读取文件内容，一次读多个字节：&quot;); // 一次读多个字符 char[] tempchars = new char[30]; int charread = 0; reader = new InputStreamReader(new FileInputStream(fileName)); // 读入多个字符到字符数组中，charread为一次读取字符数 while ((charread = reader.read(tempchars)) != -1) { // 同样屏蔽掉\\r不显示 if ((charread == tempchars.length) &amp;&amp; (tempchars[tempchars.length - 1] != '\\r')) { System.out.print(tempchars); } else { for (int i = 0; i &lt; charread; i++) { if (tempchars[i] == '\\r') { continue; } else { System.out.print(tempchars[i]); } } } } } catch (Exception e1) { e1.printStackTrace(); } finally { if (reader != null) { try { reader.close(); } catch (IOException e1) { } } } } /** * 以行为单位读取文件，常用于读面向行的格式化文件 */ public static void readFileByLines(String fileName) { File file = new File(fileName); BufferedReader reader = null; try { System.out.println(&quot;以行为单位读取文件内容，一次读一整行：&quot;); reader = new BufferedReader(new FileReader(file)); String tempString = null; int line = 1; // 一次读入一行，直到读入null为文件结束 while ((tempString = reader.readLine()) != null) { // 显示行号 System.out.println(&quot;line &quot; + line + &quot;: &quot; + tempString); line++; } reader.close(); } catch (IOException e) { e.printStackTrace(); } finally { if (reader != null) { try { reader.close(); } catch (IOException e1) { } } } } /** * 随机读取文件内容 */ public static void readFileByRandomAccess(String fileName) { RandomAccessFile randomFile = null; try { System.out.println(&quot;随机读取一段文件内容：&quot;); // 打开一个随机访问文件流，按只读方式 randomFile = new RandomAccessFile(fileName, &quot;r&quot;); // 文件长度，字节数 long fileLength = randomFile.length(); // 读文件的起始位置 int beginIndex = (fileLength &gt; 4) ? 4 : 0; // 将读文件的开始位置移到beginIndex位置。 randomFile.seek(beginIndex); byte[] bytes = new byte[10]; int byteread = 0; // 一次读10个字节，如果文件内容不足10个字节，则读剩下的字节。 // 将一次读取的字节数赋给byteread while ((byteread = randomFile.read(bytes)) != -1) { System.out.write(bytes, 0, byteread); } } catch (IOException e) { e.printStackTrace(); } finally { if (randomFile != null) { try { randomFile.close(); } catch (IOException e1) { } } } } /** * 显示输入流中还剩的字节数 */ private static void showAvailableBytes(InputStream in) { try { System.out.println(&quot;当前字节输入流中的字节数为:&quot; + in.available()); } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { String fileName = &quot;C:/temp/newTemp.txt&quot;; ReadFromFile.readFileByBytes(fileName); ReadFromFile.readFileByChars(fileName); ReadFromFile.readFileByLines(fileName); ReadFromFile.readFileByRandomAccess(fileName); } } ","link":"http://blog.801314.top/post/java-du-qu-wen-jian-wan-zheng-ban/"},{"title":"索引的作用","content":"深入浅出理解索引结构 索引可以理解为是一种特殊的目录 微软的SQL SERVER提供了两种索引： 聚集索引（也称聚类索引，簇集索引） 非聚集索引（也称非聚类索引，非簇集索引） 聚集索引和非聚集索引的区别： 1、正文内容本身就是一种按照一定规则排列的目录称为“聚集索引”，例如：汉语字典的正文本身 2、目录纯粹是目录，正文纯粹是正文的排序方式称为“非聚集索引”。需要两个过程：先在目录中找到结果，然后在正文中找到具体内容。例如：汉语字典的偏旁表。 每个表只能有一个聚集索引，因为目录只能按照一种方法进行排序。 如何使用聚集索引或非聚集索引 动作描述 使用聚集索引 使用非聚集索引 列经常被分组排序 yes yes 返回某范围内的数据 yes no 一个或极少不同值 no no 小数码的不同值 yes no 大数码的不同值 no yes 频繁更新的列 no yes 外键列 yes yes 主键列 yes yes 频繁修改索引列 no yes 事实上，我们可以通过前面聚集索引和非聚集索引的例子来理解。比如要返回某范围内的数据一项。如果有个表有一个时间列，恰好您把聚合索引建立在该列，这时您查询2004年1月1日至2004年10月1日之间的全部数据时，这个速度就将是很快的，因为您的这本字典正文是按日期进行排序的，聚类索引只需要找到要检索的所有数据中的开头和结尾数据即可；而不像非聚集索引，必须先查到目录中查到每一项数据对应的页码，然后再根据页码查到具体内容。 索引使用的误区 主键就是聚集索引 是对聚集索引的一种浪费。SQL SERVER默认是在主键上建立聚集索引。通常，我们会在每个表中都建立一个ID列，以区分每条数据，并且这个ID列是自动增大的，步长一般为1。我们的这个办公自动化的实例中的列Gid就是如此。此时，如果我们将这个列设为主键，SQL SERVER会将此列默认为聚集索引。这样做有好处，就是可以让您的数据在数据库中按照ID进行物理排序，但笔者认为这样做意义不大。 显而易见，聚集索引的优势是很明显的，而每个表中只能有一个聚集索引的规则，这使得聚集索引变得更加珍贵。 从我们前面谈到的聚集索引的定义我们可以看出，使用聚集索引的最大好处就是能够根据查询要求，迅速缩小查询范围，避免全表扫描。在实际应用中，因为ID号是自动生成的，我们并不知道每条记录的ID号，所以我们很难在实践中用ID号来进行查询。这就使让ID号这个主键作为聚集索引成为一种资源浪费。其次，让每个ID号都不同的字段作为聚集索引也不符合“大数目的不同值情况下不应建立聚合索引”规则；当然，这种情况只是针对用户经常修改记录内容，特别是索引项的时候会负作用，但对于查询速度并没有影响。 （1）仅在主键上建立聚集索引，并且不划分时间段： Select gid,fariqi,neibuyonghu,title from tgongwen 用时：128470毫秒（即：128秒） （2）在主键上建立聚集索引，在fariq上建立非聚集索引： select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt; dateadd(day,-90,getdate()) 用时：53763毫秒（54秒） （3）将聚合索引建立在日期列（fariqi）上： select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt; dateadd(day,-90,getdate()) 用时：2423毫秒（2秒） 只要建立索引就能显著提高查询速度 事实上，我们可以发现上面的例子中，第2、3条语句完全相同，且建立索引的字段也相同；不同的仅是前者在fariqi字段上建立的是非聚合索引，后者在此字段上建立的是聚合索引，但查询速度却有着天壤之别。所以，并非是在任何字段上简单地建立索引就能提高查询速度。 从建表的语句中，我们可以看到这个有着1000万数据的表中fariqi字段有5003个不同记录。在此字段上建立聚合索引是再合适不过了。在现实中，我们每天都会发几个文件，这几个文件的发文日期就相同，这完全符合建立聚集索引要求的：“既不能绝大多数都相同，又不能只有极少数相同”的规则。由此看来，我们建立“适当”的聚合索引对于我们提高查询速度是非常重要的。 把所有需要提高查询速度的字段都加进聚集索引，以提高查询速度 上面已经谈到：在进行数据查询时都离不开字段的是“日期”还有用户本身的“用户名”。既然这两个字段都是如此的重要，我们可以把他们合并起来，建立一个复合索引（compound index）。 很多人认为只要把任何字段加进聚集索引，就能提高查询速度，也有人感到迷惑：如果把复合的聚集索引字段分开查询，那么查询速度会减慢吗？带着这个问题，我们来看一下以下的查询速度（结果集都是25万条数据）：（日期列fariqi首先排在复合聚集索引的起始列，用户名neibuyonghu排在后列）： 1.（1）select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt;''2004-5-5'' 查询速度：2513毫秒 1.（2）select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt;''2004-5-5'' and neibuyonghu=''办公室'' 查询速度：2516毫秒 1.（3）select gid,fariqi,neibuyonghu,title from Tgongwen where neibuyonghu=''办公室'' 查询速度：60280毫秒 从以上试验中，我们可以看到如果仅用聚集索引的起始列作为查询条件和同时用到复合聚集索引的全部列的查询速度是几乎一样的，甚至比用上全部的复合索引列还要略快（在查询结果集数目一样的情况下）；而如果仅用复合聚集索引的非起始列作为查询条件的话，这个索引是不起任何作用的。当然，语句1、2的查询速度一样是因为查询的条目数一样，如果复合索引的所有列都用上，而且查询结果少的话，这样就会形成“索引覆盖”，因而性能可以达到最优。同时，请记住：无论您是否经常使用聚合索引的其他列，但其前导列一定要是使用最频繁的列。 索引使用经验总结 用聚合索引比用不是聚合索引的主键速度快 用聚合索引比用一般的主键作为 order by 时速度快，特别是 小数据量情况下 事实上，如果数据量很小的话，用聚集索引作为排序列比使用非聚集索引速度快的明显的多；而数据量如果很大的话，如10万以上，则二者的速度差别不明显。 使用聚合索引内的时间段，搜索时间会按数据占整个数据表的百分比成比例减少，而无论聚合索引使用列多少个： 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;''2004-1-1'' 用时：6343毫秒（提取100万条） 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;''2004-6-6'' 用时：3170毫秒（提取50万条） 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi=''2004-9-16'' 用时：3326毫秒（和上句的结果一模一样。如果采集的数量一样，那么用大于号和等于号是一样的） 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;''2004-1-1'' and fariqi&lt;''2004-6-6'' 用时：3280毫秒 日期列不会因为有分秒的输入而减慢查询速度 下面的例子中，共有100万条数据，2004年1月1日以后的数据有50万条，但只有两个不同的日期，日期精确到日；之前有数据50万条，有5000个不同的日期，日期精确到秒。 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;''2004-1-1'' order by fariqi 用时：6390毫秒 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&lt;''2004-1-1'' order by fariqi 用时：6453毫秒 注意事项 “水可载舟，亦可覆舟”，索引也是一样，索引有助于提高检索性能，但过多或不当但的索引也会导致系统低效。因为用户在表中没加进一个索引，数据库就要做更多的工作。过多的索引甚至会导致索引碎片。 改善SQL语句 很多人不知道SQL语句在SQL SERVER中是如何执行的，他们担心自己所写的SQL语句会被SQL SERVER误解。比如： 1.select * from table1 where name=''zhangsan'' and tID &gt; 10000和执行select * from table1 where tID &gt; 10000 and name=''zhangsan'' 一些人不知道以上两条语句的执行效率是否一样，因为如果简单的从语句先后上看，这两个语句的确是不一样，如果tID是一个聚合索引，那么后一句仅仅从表的10000条以后的记录中查找就行了；而前一句则要先从全表中查找看有几个name=''zhangsan''的，而后再根据限制条件条件tID&gt;10000来提出查询结果。 事实上，这样的担心是不必要的。SQL SERVER中有一个“查询分析优化器”，它可以计算出where子句中的搜索条件并确定哪个索引能缩小表扫描的搜索空间，也就是说，它能实现自动优化。 虽然查询优化器可以根据where子句自动的进行查询优化，但大家仍然有必要了解一下“查询优化器”的工作原理，如非这样，有时查询优化器就会不按照您的本意进行快速查询。 在查询分析阶段，查询优化器查看查询的每个阶段并决定限制需要扫描的数据量是否有用。如果一个阶段可以被用作一个扫描参数（SARG），那么就称之为可优化的，并且可以利用索引快速获得所需数据。 SARG的定义：用于限制搜索的一个操作，因为它通常是指一个特定的匹配，一个值得范围内的匹配或者两个以上条件的AND连接。形式如下： 列名 操作符 &lt;常数 或 变量&gt;或&lt;常数 或 变量&gt; 操作符列名 列名可以出现在操作符的一边，而常数或变量出现在操作符的另一边。如： Name=’张三’ 价格&gt;5000 5000&lt;价格 Name=’张三’ and 价格&gt;5000 如果一个表达式不能满足SARG的形式，那它就无法限制搜索的范围了，也就是SQL SERVER必须对每一行都判断它是否满足WHERE子句中的所有条件。所以一个索引对于不满足SARG形式的表达式来说是无用的。 介绍完SARG后，我们来总结一下使用SARG以及在实践中遇到的和某些资料上结论不同的经验： Like语句是否属于SARG取决于所使用的通配符的类型 如：name like ‘张%’ ，这就属于SARG 而：name like ‘%张’ ,就不属于SARG。 原因是通配符%在字符串的开通使得索引无法使用。 or 会引起全表扫描 Name=’张三’ and 价格&gt;5000 符号SARG，而：Name=’张三’ or 价格&gt;5000 则不符合SARG。使用or会引起全表扫描。 非操作符、函数引起的不满足SARG形式的语句 不满足SARG形式的语句最典型的情况就是包括非操作符的语句，如：NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT EXISTS、NOT IN、NOT LIKE等，另外还有函数。下面就是几个不满足SARG形式的例子： ABS(价格)&lt;5000 Name like ‘%三’ 有些表达式，如： WHERE 价格*2&gt;5000 SQL SERVER也会认为是SARG，SQL SERVER会将此式转化为： WHERE 价格&gt;2500/2 但我们不推荐这样使用，因为有时SQL SERVER不能保证这种转化与原始表达式是完全等价的。 IN 的作用相当与OR 语句： Select * from table1 where tid in (2,3)和Select * from table1 where tid=2 or tid=3 是一样的，都会引起全表扫描，如果tid上有索引，其索引也会失效。 尽量少用NOT exists 和 in 的执行效率是一样的 很多资料上都显示说，exists要比in的执行效率要高，同时应尽可能的用not exists来代替not in。但事实上，我试验了一下，发现二者无论是前面带不带not，二者之间的执行效率都是一样的。因为涉及子查询，我们试验这次用SQL SERVER自带的pubs数据库。运行前我们可以把SQL SERVER的statistics I/O状态打开： 1.（1）select title,price from titles where title_id in (select title_id from sales where qty&gt;30) 该句的执行结果为： 表 ''sales''。扫描计数 18，逻辑读 56 次，物理读 0 次，预读 0 次。 表 ''titles''。扫描计数 1，逻辑读 2 次，物理读 0 次，预读 0 次。 1.（2）select title,price from titles where exists (select * from sales where sales.title_id=titles.title_id and qty&gt;30) 第二句的执行结果为： 表 ''sales''。扫描计数 18，逻辑读 56 次，物理读 0 次，预读 0 次。 表 ''titles''。扫描计数 1，逻辑读 2 次，物理读 0 次，预读 0 次。 我们从此可以看到用exists和用in的执行效率是一样的。 用函数charindex()和前面加通配符%的LIKE执行效率一样 前面，我们谈到，如果在LIKE前面加上通配符%，那么将会引起全表扫描，所以其执行效率是低下的。但有的资料介绍说，用函数charindex()来代替LIKE速度会有大的提升，经我试验，发现这种说明也是错误的： 1.select gid,title,fariqi,reader from tgongwen where charindex(''刑侦支队'',reader)&gt;0 and fariqi&gt;''2004-5-5'' 用时：7秒，另外：扫描计数 4，逻辑读 7155 次，物理读 0 次，预读 0 次。 1.select gid,title,fariqi,reader from tgongwen where reader like ''%'' + ''刑侦支队'' + ''%'' and fariqi&gt;''2004-5-5'' 用时：7秒，另外：扫描计数 4，逻辑读 7155 次，物理读 0 次，预读 0 次。 union并不绝对比or的执行效率高 我们前面已经谈到了在where子句中使用or会引起全表扫描，一般的，我所见过的资料都是推荐这里用union来代替or。事实证明，这种说法对于大部分都是适用的。 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi=''2004-9-16'' or gid&gt;9990000 用时：68秒。扫描计数 1，逻辑读 404008 次，物理读 283 次，预读 392163 次。 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi=''2004-9-16'' 2.union 3.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where gid&gt;9990000 用时：9秒。扫描计数 8，逻辑读 67489 次，物理读 216 次，预读 7499 次。 看来，用union在通常情况下比用or的效率要高的多。 但经过试验，笔者发现如果or两边的查询列是一样的话，那么用union则反倒和用or的执行速度差很多，虽然这里union扫描的是索引，而or扫描的是全表。 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi=''2004-9-16'' or fariqi=''2004-2-5'' 用时：6423毫秒。扫描计数 2，逻辑读 14726 次，物理读 1 次，预读 7176 次。 1.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi=''2004-9-16'' 2.union 3.select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi=''2004-2-5'' 用时：11640毫秒。扫描计数 8，逻辑读 14806 次，物理读 108 次，预读 1144 次。 字段提取要按照“需多少、提多少”的原则，避免“select *” 我们来做一个试验： 1.select top 10000 gid,fariqi,reader,title from tgongwen order by gid desc 用时：4673毫秒 1.select top 10000 gid,fariqi,title from tgongwen order by gid desc 用时：1376毫秒 1.select top 10000 gid,fariqi from tgongwen order by gid desc 用时：80毫秒 由此看来，我们每少提取一个字段，数据的提取速度就会有相应的提升。提升的速度还要看您舍弃的字段的大小来判断。 count(*)不比count(字段)慢 某些资料上说：用*会统计所有列，显然要比一个世界的列名效率低。这种说法其实是没有根据的。我们来看： 1.select count(*) from Tgongwen 用时：1500毫秒 1.select count(gid) from Tgongwen 用时：1483毫秒 1.select count(fariqi) from Tgongwen 用时：3140毫秒 1.select count(title) from Tgongwen 用时：52050毫秒 从以上可以看出，如果用count()和用count(主键)的速度是相当的，而count()却比其他任何除主键以外的字段汇总速度要快，而且字段越长，汇总的速度就越慢。我想，如果用count(*)， SQL SERVER可能会自动查找最小字段来汇总的。当然，如果您直接写count(主键)将会来的更直接些。 order by按聚集索引列排序效率最高 我们来看：（gid是主键，fariqi是聚合索引列）： 1.select top 10000 gid,fariqi,reader,title from tgongwen 用时：196 毫秒。 扫描计数 1，逻辑读 289 次，物理读 1 次，预读 1527 次。 1.select top 10000 gid,fariqi,reader,title from tgongwen order by gid asc 用时：4720毫秒。 扫描计数 1，逻辑读 41956 次，物理读 0 次，预读 1287 次。 1.select top 10000 gid,fariqi,reader,title from tgongwen order by gid desc 用时：4736毫秒。 扫描计数 1，逻辑读 55350 次，物理读 10 次，预读 775 次。 1.select top 10000 gid,fariqi,reader,title from tgongwen order by fariqi asc 用时：173毫秒。 扫描计数 1，逻辑读 290 次，物理读 0 次，预读 0 次。 1.select top 10000 gid,fariqi,reader,title from tgongwen order by fariqi desc 用时：156毫秒。 扫描计数 1，逻辑读 289 次，物理读 0 次，预读 0 次。 从以上我们可以看出，不排序的速度以及逻辑读次数都是和“order by 聚集索引列” 的速度是相当的，但这些都比“order by 非聚集索引列”的查询速度是快得多的。 同时，按照某个字段进行排序的时候，无论是正序还是倒序，速度是基本相当的。 高效的TOP 事实上，在查询和提取超大容量的数据集时，影响数据库响应时间的最大因素不是数据查找，而是物理的I/0操作。如： 1.select top 10 * from ( 2.select top 10000 gid,fariqi,title from tgongwen 3.where neibuyonghu=''办公室'' 4.order by gid desc) as a 5.order by gid asc 这条语句，从理论上讲，整条语句的执行时间应该比子句的执行时间长，但事实相反。因为，子句执行后返回的是10000条记录，而整条语句仅返回10条语句，所以影响数据库响应时间最大的因素是物理I/O操作。而限制物理I/O操作此处的最有效方法之一就是使用TOP关键词了。TOP关键词是SQL SERVER中经过系统优化过的一个用来提取前几条或前几个百分比数据的词。经笔者在实践中的应用，发现TOP确实很好用，效率也很高。但这个词在另外一个大型数据库ORACLE中却没有，这不能说不是一个遗憾，虽然在ORACLE中可以用其他方法（如：rownumber）来解决。在以后的关于“实现千万级数据的分页显示存储过程”的讨论中，我们就将用到TOP这个关键词。 到此为止，我们上面讨论了如何实现从大容量的数据库中快速地查询出您所需要的数据方法。当然，我们介绍的这些方法都是“软”方法，在实践中，我们还要考虑各种“硬”因素，如：网络性能、服务器的性能、操作系统的性能，甚至网卡、交换机等 ","link":"http://blog.801314.top/post/suo-yin-de-zuo-yong/"},{"title":"Java 基础篇","content":"让程序性能优异的并发利器 线程池 创建参数对工作机制对影响 线程池构造函数： public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler) 参数含义： corePoolSize 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize； 如果当前线程数=corePoolSize，继续提交的任务会被保存到阻塞队列中，等待被执行； 如果执行了线程池的 prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。 maximumPoolSize 线程池允许的最大线程数。 如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于 maximumPoolSize; keepAliveTime 非核心线程空闲时的存活时间，当没有任务执行时，非核心线程继续存活的时间。 默认情况下，该参数只在线程数大于corePoolSize时才有用。 TimeUnit keepAliveTIme的时间单位。 workQueue workQueue必须是BlockingQueue阻塞队列。 当线程池中的线程数超过他的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。通过workQueue，线程池实现了阻塞功能。 workQueue 用于保持等待执行任务的的任务阻塞队列，尽量使用有界队列，因为无界队列会对线程池有影响： 1、当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因为线程池中的线程数不会超过corePoolSize； 2、使用无界队列时，maximumPoolSize和keepAliveTime将是无效参数 3、使用无界queue可能会耗尽系统资源，有界队列则有助于防止资源耗尽，同时即使使用有界队列，也要控制队列的大小在一个合适的范围。 所以一般使用 ArrayBlockingQueue，LinkedBlockingQueue，SynchronousQueue，PriorityBlockingQueue threadFactory 创建线程的工厂。 通过自定义的线程工厂，可以给每个新建的线程设置一个具有识别度的线程名，当然还可以更加自由的对线程做更多的设置，比如设置所有的线程为守护线程。 Exexutors 静态工厂里默认的threadFactory，线程的命名规则是“pool-数字-thread-数字” RejectedExecutionHandler 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，即当前线程数已经达到最大线程数，如果继续提交任务，必须采取一种策略处理该任务。 线程池提供了4中策略： 1、AbortPolicy：直接抛出异常，默认策略 2、CallerRunsPolicy: 用调用者所在的线程来执行任务 3、DiscardOlderestPolicy： 丢弃阻塞队列中靠最前的任务，并执行当前任务 4、DiscardPolicy: 直接丢弃任务 也可以根据应用场景实现 RejectedExecutionHandler接口，自定义饱和策略，如记录日志活持久化存储不能处理的任务。 合理配置线程池 首先分析任务特性： * 任务的性质：CPU密集型，IO密集型和混合型任务 * 任务的优先级：高，中，低 * 任务的执行时间：长，中，短 * 任务的依赖性：是否依赖其他系统资源，如数据库链接 性质不同的任务可以用不同规模的线程池分开处理 CPU 密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。 IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如 2*Ncpu。 混合型的任务，如果可以拆分，将其拆分为一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。 可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。 概述 ConcurrentHashMap 基本概述 ConcurrentHahsMap 是线程安全的Map，1.7 和 1.8 中实现方式不同 1.7 采用分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 1、segment继承ReentrantLock（重入锁）用来充当锁的角色，每个Segemnt 对象守护每个散列映射表的若干个锁。 2、HashEntry 用来风中映射表的键值对 3、每个桶是由若干个HashEntry 对象链接起来的链表 1.8 采用 Node+CAS+Synchronized 来保证并发安全。取消类Segment，直接用table数组存储键值对；当HashEntry对象组成对链表长度超过 TREEIFY_ THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。 1、重要对常量： private transient volatile int sizeCtl; 当为负数时，-1表示正在初始化，-N表示 N -1 个线程正在进行扩容； 当为 0 时，表示 table 还没有初始化； 当为其他正数时，表示初始化或者下一洗进行扩容的大小。 2、 数据结构： Node时存储结构的基本单元，实现了Map中的Entry接口，用于存储数据； TreeNode继承Node，但是数据结构换成来二叉树结构，是红黑树的存储结构，用于红黑树中存储数据。 3、存储对象时（put（） 方法） 1、如果没有初始化，就调用initTable（）方法来进行初始化； 2、如果没有 hash 冲突就直接 CAS 无锁插入； 3、如果需要扩容，就先进行扩容； 4、如果哦存在hash冲突，就枷锁来保证线程安全，两种情况：一种时链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入； 5、如果该链表的数量大雨阈值8，就要先转换成红黑树的结构 6、如果添加成功就调用 addCount（）方法统计size，并坚持是否需要扩容。 4、扩容方法 transfer（） 默认容量为16，扩容是，容量变为原来的两倍 helpTransfer（）： 调用多个工作线程一起帮助进行扩容，效率更高 5、获取对象时（get（）方法） 1、计算hash值，定位到该table索引位置，如果是首节点符合就返回； 2、如果遇到扩容时，会标记正在扩容结点 ForwardingNode.find() 方法，查找该结点，匹配就返回； 3、以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null 为什么hashmap1.8 不直接使用红黑树而还要保留链表 因为插入时红黑树需要进行左旋，右旋操作，而单链表不需要，在数量较少时，红黑树并没有表现出比链表更好的查询效率，而且在占用空间上，红黑树的节点比链表的节点更大，时链表的两倍。 为什么大于8个的时候才转换红黑树 1、 按照JDK源码的解释： TreeNodes占用空间是普通Nodes的两倍，所以只有当bin包含足够多的节点时才会转成TreeNodes，而是否足够多就是由 TREEIFY_THRESHOLD的值决定的。当bin中节点数变少时，又会转成普通的bin。TREEIFY_THRESHOLD的值是这个空间和时间的权衡。 当hashCode离散性很好的时候，树形bin用到的概率非常小，因为数据均匀分布在每个bin中，几乎不会有bin中链表长度会达到阈值。 但是在随机hahsCode下，离散性可能会变差，然而JDK又不能阻止用户实现这种不好的hash算法，因此就可能导致不均匀的数据分布。 不过理想情况下随机 hashCode 算法下所以bin中节点的分布频率会遵循泊松分布，一个bin中链表长度达到8个元素的概率为 0.00000006，几乎是不可能时间。所以，之所以选择8，不是拍拍屁股决定的，而是根据概率统计决定的。 2、网上的说法： 红黑树的平均查找长度是 log(n), 如果长度为8，平均查找长度为 log(8)=3，链表的平均查找长度为n/2，当长度为8是，平均查找长度为8/2=4，这才有转换成树的必要；链表长度如果小于等于6，6/2=3，而log(6)=2.6, 虽然速度也很快，但是转化为树结构和生成树的时间并不会太短。 概述volatile volatile 关键字的主要作用： 多线程主要围绕可见性和原子性两个特性而展开，使用volatile 关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据。但是volatile不能保证操作的原子性，对任意单个volatile变量的读/写具有原子性，但类似++这种复合操作不具有原子性。 代码底层在执行时为了获取更好的性能会对指令进行重排序，多线程下可能会出行一些意想不到的问题。使用volatile则会禁止重排序，但是会降低代码的执行效率。 同时在内存语义上，当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存，当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 在java中，对与volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序问题、强制刷新和读取。 在具体实现上，volatile关键字修饰的变量会存在一个“lock：”的前缀。它不是一种内存屏障，但是它能完成类似内存屏障的功能，lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。 同时该指令会将当前处理器缓存行的数据直接写回到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。 概述AQS AQS是用来构建锁或者其他同步组件的基础框架，比如ReentrantLock、ReentrantReadWriteLock 和 CountDownLatch 就是基于AQS实现的。 它使用了一个int成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。踏实CLH队列锁的一种变体实现。它可以实现2种同步方式：独占式，共享式。 AQS的主要使用方式式继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，同步器的设计基于模版方法模式，所以如果要实现我们自己的同步工具类就需要覆盖其中几个可以重写的方法：tryAcquire，tryReleaseShared 等。 这样设计的目的是同步组件（比如锁）是面向使用者的，它定义来使用者于同步组件交互的接口（比如可以允许两个线程并行访问），隐藏来实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。这样可以很好的隔离使用者和实现者所需要关注的领域。 在内部，AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。该队列由一个一个的Node节点组成，每个Node节点维护一个prev引用和next引用，分别指向自己的前驱和后继节点，构成一个双端双向链表。 同时与Condition相关的等待队列，节点类型也是Node，构成一个单向链表。 synchronized 的实现原理 synchronized 在JVM里的实现都是基于进入和退出的Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的 MonitorEnter 和 MonitorExit 指令来实现。 对同步块，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor到所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。 对同步方法，从同步方法反编译对结果来看，方法对同步并没有通过指令monitorEnter和monitoerExit来实现，相对于普通方法，其常量池中多来 ACC_SYNCHRONIZED 标示符。 JVM就是根据该标示符来实现方法的同步的： 当方法被调用时，调用指令将会坚持方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后在释放monitor。在方法执行期间，其他任何线程都无法在获得同一个monitor对象。 synchronized使用的锁是存放在Java对象头里面，具体位置是对象头里面的MarkWord，MarkWord 里默认数据是存储对象的HashCode 等信息，但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式。在具体优化上，从1.6开始引入了偏向锁、自旋锁等机制提升性能。 什么是CAS操作，缺点是什么？ CAS的基本思路是：如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事，但是要返回原值是多少。每个CAS操作过程都包含三个运算符：一个内存地址V, 一个期望的值A 和 一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。 CAS 缺点： ABA问题： 一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，最终又变回A，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜在但问题。从Java1.5开始，JDK的atomic包里提供了一个类的AtomicStampedReference来解决ABA问题。 循环时间长，开销大： 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时间就可以用锁。 性能等奠基之石，SQL优化 Mysql索引类型和区别 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引：索引列的值必须唯一，但允许有空值 复合索引：一个索引包含多个列 聚集索引（聚蔟索引）：innodb, 数据和索引放到一起 非聚集索引：myisam，数据和索引文件分开存放 事务等四大特性 如果一个数据库声称支持事务但操作，那么该数据库必须具备以下四个特性： 原子性 是指事务包含的操作要么全部成功，要么全部失败回滚。因此事务的操作如果成功就完全应用到数据库，如果操作失败则不能对数据库有任何影响。 一致性 是指事务必须使数据库从一个一致性状态变化到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 拿转账来说，假设用户A和用户B的钱加一起是200，无论A和B直接如何转账，转几次账，事务结束后两个用户的钱加一起还是200，这就是事务的一致性。 隔离性 是当多个用户并发访问数据库时，比如操作同一张表是，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发的执行。 持久性 是指一个事务一旦被提交列，那么对数据库中对数据对改变就是永久性对，即使是在数据库系统遇到故障对情况下也不会丢失提交对事务的操作。 事务的隔离级别 不考虑事务的隔离性会发生的问题 脏读 在一个事务处理过程里读取里了另一个未提交的事务中的数据。 当一个事务正在多次修改某个数据，而在这个事务中这多次的修改还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。 不可重复读 是指在对于数据库中的某个数据，一个事务范围内多次查询却返回来不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他买单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务并提交完）。程序员就会很郁闷，明明卡里是有钱的… 不可重复读和脏读的区别： 脏读是某一税务读取了另一个事务未提交的脏数据 不可重复读是读取了前一事务提交的数据 在某些情况下，不可重复读并不是问题，比如给我们多次查询某个数据当然是以最后查询得到的结果为主。 虚读（幻读） 幻读是事务非独立执行时发生的一种现象。例如事务T1 对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是“1”，并提交给了数据库。而操作T1的用户如果在查看刚刚修改的数据，就会发现还有一行没有修改，其实这行是T2中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体。 数据库提供的隔离级别 Read uncommitted(读未提交)： 顾名思义，就是一个事务可以读取另一个未提交的事务的数据。最低级别，任何情况都无法保证。 Read committd （读已提交） 一个事务要等另一个事务提交后才能读取数据。可避免脏读等发生，但是无法避免不可重复读。 Repeatable read（可重复读） 就是在开始读取数据时，不再允许修改操作，可避免脏读、不可重复读的发生。但是无法避免幻读。 Serializable（串行化） 是最高的事务隔离级别，在该级别下，事务串行化执行，可避免脏读，不可重复读，幻读的发生。 就是以锁表的方式（类似于Java多线程中的锁）使其他的线程只能在锁外等待，这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 以上四种隔离级别最高的是Serializable级别，最低的是 Read uncommitted 级别，当然级别越高，执行的效率越低。所以平时选用何种隔离级别应该根据实际情况。在MySql数据库中默认的隔离级别为Repeatable read（可重复读）。 在Mysql数据库中，支持上面四种隔离级别，默认的为 Repeatable read；而在Oracle 数据库中，只支持Serializable级别和Read committed这两种级别，默认为 Read committed 级别。 MySQL事务的实现原理 事务具有ACID四个特性。也就是：原子性，一致性，隔离性，持久性。ACD三个特性是通过 Redo log（重做日志）和 Undo log 实现的。而隔离性是通过锁来实现的。 重做日志（Redo log）用来实现事务的持久性，即D特性。它由两部分组成： 内存中的重做日志缓冲 重做日志文件 在事务提交时，必须先将事务的所以日志写入到redo日志文件中，待事务的commit操作完成才算整个事务操作完成。 Undo log，它可以实现如下两个功能： 事务回滚 实现MVCC（多版本并发控制） undo log 可以认为当delete 一条记录时，undo log中会记录一条对应的 insert 记录，反之亦然，当update 一条记录时，它记录一条对应相反的update 记录。 SQL优化 常见步骤： 环境方面 尽可能的使用高速磁盘和大内存 服务器使用Linux，并且进行操作系统级别的调优，比如网络参数，避免使用swap交换区等等 SQL相关 先找到慢查询日志，就是查询慢的日志，是指mysql记录所有执行超过long_query_time 参数设定的时间阈值的SQL语句的日志。该日志能为SQL语句的优化带来很好的帮助。默认情况下，慢查询日志是关闭的，要使用慢查询日志功能，首先需要开启慢查询日志功能。 slow_query_log 启动/停止慢查询 slow_query_log_file 指定慢查询日志的存储路径及文件（默认和数据文件放在一起） long_query_time 指定记录慢查询日志SQL执行时间的阈值（单位：秒，默认10秒） log_queries_not_using_indexed 是否记录未使用索引的SQL log_output 日志存放的地方【table】，【file】，【file，table】 分析慢查询日志。慢查询的日志记录非常多，要从里面找寻一条慢查询的日志并不少很容易的事情，一般需要一些辅助工具才能快速定位需要优化的SQL语句，比如 Mysqldumpslow SQL本身优化，比如少用子查询，in查询改关联查询，不实用外键与级联等 反范式设计，字段允许适当冗余，选择合适的字段存储长度等 使用执行计划分析SQL语句，使用EXPLAN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能平静下来，至少可以知道： * 表的读取顺序 * 数据读取操作的操作类型 * 哪些索引可以使用 * 哪些索引被实际使用 * 表之间的引用 * 每张表有多少行被优化器查询 比如，执行计划中的type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是： system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; rang &gt; index &gt; ALL 一般来说，得保证查询至少达到 rang 级别，要求能达到 ref。 优化10大策略 尽量全值匹配 当建立了索引列后，能在where条件中使用索引的尽量使用。 最佳左前缀法则 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 不在索引列上做任何操作 不在索引列上做任何操作（计算，函数，手动/自动的类型转换），会导致索引失效而转向全表扫描 范围条件放最后 中间有范围查询回导致后面的索引列全部失效 覆盖索引尽量用 尽量使用覆盖索引（指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取），减少select *； 不等于要慎用 mysql 在使用不等于（!= 或 &lt;&gt;）的时候无法使用索引，会导致全表扫描，如果一定要使用不等于，请使用覆盖索引。 Null/Not 有影响 使用is null 或 is not null 会导致索引失效 解决方式：覆盖索引 Like 查询要当心 like 以通配符开头（'%abc..'）,mysql 索引会失效，变成全表扫描 解决方式：覆盖索引 字符类型加引号 字符串不佳单引号导致索引失效，变成全表扫描 解决方式：加引号 OR 改 UNION 效率高 解决方式：如果一定要用OR，那么使用覆盖索引 JVM JVM 内存区域 JVM在执行Java 程序的过程中会把它管理的内存分为若干个不同的区域，这些组成部分有些是线程私有的，有些则是线程共享的。 线程私有的：程序计数器，虚拟机栈，本地方法栈 线程共享的：方法区，堆 程序计数器 较小的内存空间，当前线程执行的字节码的行号指示器；各线程之间独立存储，互不影响，此内存区域是唯一一个不会出现 OutOfMemoryError 请求的区域。 虚拟机栈 每个线程私有的，线程在运行时，在执行每个方法的时候都会打包成一个栈帧，存储了局部变量表，操作树栈，动态链接，方法出口等信息，然后放入栈。每个时刻正在执行的当前方法就是虚拟机栈顶的栈帧。方法的执行就对应着栈帧在虚拟机栈中入栈和出栈的过程。 本地方法栈 各虚拟机自由实现，本地方法栈 native 方法调用 JNI 到了底层的 C/C++(c/c++ 可以出发汇编语言，然后驱动硬件) 方法区/永久代 用于存储已经被虚拟机加载的类信息，常量（&quot;zdy&quot;,&quot;124&quot;等），静态变量（static变量）等数据，比如类信息就包括类的完整有效名，返回值类型，修饰符（public，private。。。），变量名，方法名，方法代码，这个类型直接父类的完整有效名（除非这个类型是 interface 或者 java.lang.Object,两种情况下都没有父类），类的直接接口的一个有序裂变等等。 堆 几乎索引对象都分配在这里，也是垃圾回收发生的主要区域 JVM垃圾回收器 JVM中是通过可达性分析算法判断对象是否可回收的。 这个算法的基本思想就是通过一系列的称为“GC Roots”的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连的话，则证明此对象不可用的。 在垃圾回收上，又几种常见的算法： 标记-清除算法 标记-清除算法分为“标记”和“清除”阶段：首先标记出所以需要回收的对象，在标记完成后统一回收所以被标记的对象。但是会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 复制算法 将内存氛围大小相同的两块，每次使用其中的一块。当一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 标记-整理算法 根据老年代代特点设计的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所以存活的对象向一段移动，然后直接清理掉端边界以外的内存。 根据对象的生命周期，将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 在具体的垃圾算法的实现上又几种垃圾回收器。 Serial/Serial Old 最古老的，单线程，独占式，成熟，适合CPU 服务器 -XX:+UseSerialGC 新生代和老年代都用串行收集器 -XX:+UseParNewGC 新生代使用ParNew, 老年代使用 Serial Old -XX:+UseParallelGC 新生代使用ParallerGC，老年代使用Serial Old ParNew 和Serial 基本没有区别，唯一区别：多线程，多CPU多，停顿时间比Serial少 -XX:+UseParNewGC 新生代使用ParNew，老年代使用Serial Old 除了性能原因外，主要是因为除了 Serial 收集器，只有他能与CMS收集器配合工作。 Parallen Scavenge (ParallerGC) /Parallel Old 关注吞吐量的垃圾收集器，高吞吐量则可以高效的利用CPU事件，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 所谓吞吐量就是CPU用于运行用户代码的事件与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/(运行哦用户代码时间 + 垃圾收集时间)，虚拟机总共运行了 100 分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 -XX:+UseParalleOldGC 则会开启这一对组合，同时Parallel Scavenge还有一个自适应调整策略，就不需要手工指定新生代的大小（-Xmn），Eden与Survivor区的比例（-XX:SurvivorRatio)，晋升老年代对象年龄（-XX:LPretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量。通过打开-XX：+UseAdaptiveSizePolicy, 只需要把基本你的内存数据设置好（如-Xmx 设置最大堆），然后使用 MaxGCPauseMillis 参数（更关注最大停顿时间）或 GCTimeRatio参数（更关注吞吐量）给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。 Concurrent Mark Sweep（CMS） 收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务器的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。 -XX:+UseConcMarkSweepGC, 一般新生代使用ParNew，老年代的用CMS，并发收集失败，转为SerialOld. 从名字（包含“Mark Sweep”）可以看出，CMS收集器是基于“标记-清楚”算法实现的，它的运作过程相对于前面集中收集器来说更复杂一些。 整个过程分为4个步骤： 初始标记：纠结是标记一下 GC Roots 能直接关联到的对象，速度最快，需要停顿（STW--stop the world） 并发标记：从GC Roots 开始对堆中对象进行可达性分析，找到存活对象，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记变动的那一本部分对象的标记记录，需要停顿。这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 并发清除：不需要停顿。 优点： 由于整个过程中耗时最长的并发标记和并发清除过程周几去线程都可以和用户线程一起工作，所以，总体来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 缺点： CPU资源敏感：因为并发阶段多线程占用CPU资源，如果CPU资源不足，效率会明显降低。 浮动垃圾：由于CMS并发清理阶段 用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在档次收集中处理掉他们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。 由于浮动垃圾的存在，因为需要预留出一部分内存，意味着CMS收集不能像其他收集器那样等待老年代快满 的时候再回收。 再1.6的版本中，老年代空间使用率阈值（92%） 如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Filure，这时虚拟机将临时启用 Serial Old来代替CMS。 产生空间碎片：标记-清除算法会导致产生不联系的空间碎片，CMS只会删除无用的对象，不会对内存做压缩，会造成内存碎片。 G1垃圾回收器 主要是用在大内存和多处理器数量的服务器上。jdk9 中将G1 变成默认的垃圾收集器。 G1中重要参数： -XX:_UseG1GC 使用G1垃圾回收器 -XX:MaxGCPauseMillis=200 设置GC的最大暂停时间为200ms 内部布局改变 G1把堆划分为多个大小相等的区域（Region），每个Region大小为2的倍数，范围在1MB-32MB之间，可能为1，2，4，8，16，32MB。所有的Region有一样的大小，JVM生命周期内不会改变。整个堆被划分为2048左右个Region。新生代和老年代不再物理隔离。Region可以说是G1回收器一次回收的最小单元。 算法：标记-整理（old，humongous） 和 复制回收算法（survivor）。 Stop The World 现象 Stop The World机制，简称STW，主要指执行垃圾收集算法时，Java应用程序的其他所有除了垃圾回收线程之外的线程都被挂起。 此时，系统只能允许GC线程进行运行，其他线程则会全部暂停，等待GC线程执行完才能再次运行。这些工作都是由虚拟机在后台自动发起和自动完成的，是在用户不可见的情况下把用户正常工作的线程全部停下，这对于很多应用程序，尤其是那些对于实时性要求很高的程序来说是难以接受的。我们GC调优的目标就是尽可能的减少STW的时间和次数。 JVM中存在哪些引用 强引用 大部分引用都是强引用，这是最普遍的引用类型。 A a = new A(); 如果一个对象具有强引用，垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出 OutOfMemoryError 错误，是程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 软引用 如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的告诉缓存。 软引用可以和一个引用队列（ReferenceQuence）联合使用，如果软引用所引用的对象被垃圾回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用 可有可无。弱引用与软引用的区别：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了至于有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用 顾名思义，就是形同虚设，徐银银并不会决定对象的声明周期。如果哦一个对象仅持有虚引用，那么它就和没有任何引用一样，在任务时候都可能被来及回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 在程序设计中除了强引用，使用软引用的情况较多，这是因为软引用可以加速JVM对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出等问题的产生。 类加载机制 类从被加载到虚拟机内存中开始，到卸载出内存位置，它的整个生命周期包括：加载，验证，准备，解析，初始化，使用和卸载 7个阶段。其中验证，准备，解析 3各部分统称为连接（Linking） 加载 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class 对象，作为方法区这个类的各种数据的访问入口 验证 连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。但从哪个整体来看，验证阶段大致上会完成4个阶段的检验动作：文件格式验证，元数据验证，字节码验证，符号引用验证。 准备 正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念。首先，这时候进行内存分配的仅包括类变量（static 修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为： public staic int value = 123; 那变量初始阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value 赋值为123的putstatic指令是程序被编译后，存放于类构造器() 方法中，所以把 value 赋值为 123 的动作将在后面的初始化阶段才会执行。 假设类变量value的定义为： public static final int value = 123 编译时javac将会为value生成 ConstantValue属性，在准备阶段虚拟机就跟根据 ConstantValue 的设置将value赋值为123. 解析 是虚拟机将常连池内的符号引用替换为直接引用的过程。 符合引用以一组符号来描述所引用的目标，符号可以说任何形式的字面量，只要使用时能无歧义的定位到目标即可。符号引用于与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是直接指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会像他。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化 虚拟机规范则是严格规定了有且只有5种情况必须立即对类进行“初始化”（而加重，验证，准备自然需要在此之前开始）： 遇到new，getstatic，putstatic或invokestatic 这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最长久的Java代码场景是：使用new 关键字实例化对象的时候，读取或设置一个类的静态字段（被final修饰，已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用 java.lang.reflect 包的方法对类的进行反射调用的时候，如果类还没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类。 当使用JDK1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic,RED_putstatic,REF_invokestatic的方法局部，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 初始化也是类加载的最后一步，前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源。 从另一个角度表达：初始化阶段是执行类构造器() 方法的过程。() 方法是由编译期自动收集类中的所有类变量的赋值动作和静态语句块（statiic{}) 中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的。 () 方法对于类或接口并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成 () 方法。 虚拟机会保证一个类的 () 方法在多线程环境中被正确的加锁，同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的（）方法，其他线程都需要阻塞等待直到活动线程执行() 方法完毕。如果在一个类的() 方法中有韩式很长的操作，就可能造成多个进程阻塞。所以类的初始化是线程安全的，项目中可以利用这点。 双亲委派模型 对任意一个类，都需要由加载它的类加载器和这个类本身一起确立其在Java虚拟机中的唯一性。 从Java虚拟机的角度来讲，只存在两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader） 这个类加载器使用C++语言实现，是虚拟机的一部分。这个类将负责将存放在&lt;JAVA_HOME&gt;/lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载带虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替就可以。 其他类加载器 这些类加载器都由Java语言实现，独立于虚拟机外部，并且全部继承自抽象类 java.lang.ClassLoader 扩展类加载器 （Extension ClassLoader) 这个加载器由 sun.misc.Launcher$ExtClassLoader 实现，它负责加载&lt;JAVA_HOME&gt;/lib/ext 目录中的，或者被 java.ext.dirs 系统变量所指定的路径中的所以类型，开发者可以直接使用扩展类加载器。 应用程序类加载器 (Application ClassLoader) 这个类加载器由 sun.misc.Launcher$AppClassLoader 实现。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，所以一般也称它为系统类加载器。他负责加载用户类路径(ClassPath) 上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义的类加载器，一般情况下这个就是程序中默认的类加载器。 我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自定义的类加载器。 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承(Inheritance) 的关系来实现，而是都使用组合（omposition) 关系来复用父加载器的代码。 使用双亲委派模型来组织类加载器之间的关系，一个显而易见的好处就是Java类随着它的类加载器一起将具备了一种带有优先级的层次关系。例如类 java.lang.Object, 它存放在rt.jar 之中，无论哪一个类加载器要加载这个类，最终都会委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各类加载器环境中都是同一个类。 ClassLoader 中的 loadClass 方法中的代码逻辑就是双亲委派模型： 在自定义ClassLoader的子类的时候，我们常见的会有两种做法，一种是重写 loadClass 方法，另一种是重写 findClass方法 。其实这两种方法本质上长不大，毕竟loadClass 也会调用findClass， 但是从逻辑上讲我们最好不要直接修改 loadClass 的内部逻辑。我建议的做法是只在 findClass 里findClass 里重写自定义类的加载方法。 loadClass这个方法是实现双亲委派模型逻辑的地方，擅自修改这个方法会导致模型被破坏，容易造成问题。因此我们最好是在双亲委派模型框架内进行小范围的改掉，不破坏原有的稳定结构。同时，也避免了自己重写 loadClass 方法的过程中鼻血重写双亲委托的重复代码，从代码的复用性来看，不直接修改这个方法始终是比较好的选择。 但是Tomcat 中没有完全遵守双亲委派模型。 双亲委派模型的破坏 双亲委派模型很好的解决了各个类加载器的基础类的统一问题（越基础的类越由上层的加载器进行加载），基础类之所以称为“基础”，是因为他们总是作为被用户代码调用的API。如果基础类要调用用户的代码，那怎么办？ 比如JDBC是原生的JDBC中Driver驱动本身只是一个接口，并没有具体实现，具体的实现由不同数据库类型去实现的。 例如，MySQL的mysql-connector.jar 中的Driver类具体实现的。原生的JDBC中的类是放在 rt.jar 包的，是由启动类加载器进行加载的，在JDBC中的Driver类中需要动态去加载不同数据库类型的Driver类，而mysql-connector.jar 中的Driver类是由独立厂商实现并部署在应用程序的ClassPath下的，那启动类加载器肯定是不能进行加载的，既然是自己编写的代码，那就需要由应用程序启动类去进行类加载。 于是，这个时候就引入线程上下文类加载器（Thread Context ClassLoader）。有了这个东西，程序就可以把原本需要由启动类加载器进行加载的类，由应用程序类加载器去进行加载了。如果创建线程时还未设置，他将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那么这个类加载器默认就是应用程序类加载器。 Java中所以设计SPI的加载动作基本上都是采用这种方式，例如 JNDI，JDBC，JCE，JAXB和JBI等。 双亲委派模型的“被破坏”是由于用户对程序动态性的追求而导致的，这里说说的“动态性”指的是当前一些非常“热门“的名词：代码热替换（HotSwap），模块热部署（HotDeplooyment）等等。 JVM常用工具 jps 列出当前机器上正在运行的虚拟机进程，Jps从操作系统的临时目录上去找 * -q: 仅仅线上进程 * -m：输出主函数传入的参数， * -l：输出应用程序主类完整package名称或jar完整名称 * -v：列出jvm参数，-Xms20m -Xmx20 是启动程序指定的JVM参数 jstat 是用于见识虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载，内存，垃圾收集，JIT编译等运行数据，在没有GUI图像件，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 假设需要每 250 毫秒查询一次进程 13616 垃圾收集状况，一共查询 10 次， 那命令应当是：jstat -gc 13616 250 10 常用参数： -class 类加载器 -compiler JIT -gc GC堆状态 -gccapacity 各区大小 -gccause 最近一次GC统计和原因 -gcnew 新区统计 -gcnewcapacity 新区大小 -gcold 老区统计 -gcoldcapacity 老区大小 -gcpermcapacity 永久区大小 gcutil GC统计汇总 printcompilation HotSpot编译统计 jinfo 查看和修改虚拟机参数 -sysprops 可以查看有 System.getProperties() 取得的参数 -flag 未被显示指定的参数的系统默认值 -flags 显示虚拟机的参数 jmap 用于生产对转储快照（一般称为heapdump或dump文件）。jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列，java堆和永久带的详细信息，如空间使用率，当前用的是哪种收集器等。和info命令一样，jmap有不少功能在windows 平台下都是受限的，除了生成dump文件的-dump选项和用于查看每个类的实例，空间占用统计的 -histo选项在所有操作系统都提供之外，其余选项都只能在Linux、Solaris下使用。 jmap -dump:live,format=b,file=heap.bin Sun JDK 提供jhat（JVM heap Analysis Tool）命令与jmap搭配使用，来分析jamp 生成的对转储快照。 jhat jhat dump 文件名 屏幕显示 ”server is ready“的提示后，浏览器中访问 http://localhost:7000/ 就可以访问详情 使用jhat可以在服务器上生成堆转储文件分析（一般不推荐，比较占用服务器资源） jstack Strack Trace Java， 命令用于生产虚拟机当前时刻的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁，死循环，请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。 在代码中可以用 java.lang.Thread 类的 getAllStrackTraces() 方法用于获取虚拟机中所有线程的 StackTraceElement 对象。使用这个方法可以通过简单的几行代码就完成 jstack 的大部分功能，在实际项目中不妨调用这个方法做一个管理员页面，可以随时使用浏览器来查看线程堆栈。 项目内存或者CPU占用过高如何排查 针对CPU的问题： 查看问题进程，得到进程PID： top -c 查看进程里的线程明细，并手动记下CPU异常的线程PID：top -p PID -H 使用jdk提供的jstack命令打印出项目堆栈：jstack pid &gt; dump.log 针对内存的问题： 查看内存中的存活对象统计，找出业务相关的类名： jmap -histo:live PID &gt; xxx.log 通过简单的捅进还是没办法定位问题的话，就输出内存明细来分析。这个命令会将内存里的所有信息都输出，输出的文件大小和内存大小基本一致。而且会导致应用暂时挂起，所有谨慎使用：jmap -dump:live,format-b,file=xxx.hprof PID 最后对dump出来的文件进行分析。文件大小不是很大的话，使用jdk自带的jhat命令即可： jhat -J -mx2G -port 7170 dump 文件太大的话，可以使用 jprofiler 工具来分析。 需要分析GC的情况，可以使用一下命令： jstat -gc PID 框架源码，CRUD和高级程序员的分水岭 谈谈依赖注入和面向切面 谈谈你对Spring框架的理解，谈谈Spring中的IOC和AOP概念 Spring 框架是一个开源而轻量级的框架，是一个IOC和AOP的容器，spring的核心就是控制反转（IOC）和面向切量编程（AOP） IOC 面向对象编程中的一种设计原则，用来降低代码之间的耦合度，使整个程序体系结构更加灵活，与此同时将类的创建和依赖关系卸载配置文件里，由配置文件注入，达到松耦合的效果。与此同时IOC也称为DI（依赖注入），依赖注入是一种开发模式；依赖注入提倡使用接口编程；依赖注入使得可以开发各个组件，然后根据组件之间的依赖关系注入组装， 所谓依赖，从程序的角度看，就是比如A要调用B的方法，那么A就依赖于B，返回A要用到B，则A依赖于B。所谓倒置，如果不倒置，因为A必须要用到B，所以要有B才可以调用B的方法。不倒置的话A就需要主动获取B的实例：B b = new B(); 这就是最简单的获取B实例的方法（各种设计模式也可以帮忙去获得B的实例，比如工厂，Locator等），然后就可以调用b对象了。所以不倒置，就需要A主动获取B，才能使用B。倒置的话，就是A要调用B的话，A并不需要主动获取B，而是由其他人自动将B送上门。 AOP 面向切面编程将安全，事物等程序逻辑相对独立的功能抽取出来，利用Spring的配置文件将这些功能插进去，实现了按照切面编程，提高了复用性；最主要的作用: 可以再不锈钢源代码的情况下，给目标方法动态添加功能。 面向切面编程的目标就是分离关注点。什么是关注点呢？就是你要做的事，就是关注点。 AOP的好处就是你只需要干你的正事，其他事情交给别人帮你干。 从Spring的角度来看，AOP最大的用途就在于提供了事务管理能力。事务管理就是一个关注点，你的正事是去访问数据库，而你不太想管事务，所以，Spring在你访问数据库之前，自动帮你开启事务，当你访问数据库结束后，自动帮你提交、回滚事务。 Spring优点 低侵入式设计，独立于各种应用服务器 依赖注入的特点将组件关系透明化，降低耦合度 与第三方框架具有良好的整合效果 Spring框架中bean实例化的流程 Spring Bean的生命周期 Spring在Bean创建过程中是如何解决循环依赖的 循环依赖只会存在单例实例中，多例循环依赖直接报错。 A类实例化后，把实例放map中，A类中有一个B类属性，A类实例化要进行IOC依赖注入，这时候B类需要实例化，B类实例化跟A类一样，实例化后放入map容器中。B类中有一个A类属性，接着B类的IOC过程，又去实例化A类，这时候实例化A类过程中从map容器发现A类已经在容器中了，就直接返回了A的实例，依赖注入到B类中A属性中，B类IOC完成后，B实例化就完全完成了，就返回给A类的IOC过程。这就是循环依赖的解决。 AOP实现流程 aop:config 自定义标签解析 自定义标签解析时会执行到aop入口类中 Bean实例化过程中会执行到aop入口类中 在aop入口类中，判断当前正在实例化的类是否在pointcut中，pointcut可以理解为一个模糊匹配，是一个joinpoint的集合 如果当前正在实例化的类在pointcout中，则返回该bean的代理类，同时把所有配置的advice封装成 MethodInterceptor对象加入到容器中，封装成一个过滤器链 代理对象调用，jdk动态代理会调用invocationHandler中，cglib型代理调到 MethodInterceptor的callback类中，然后在 invoke 方法中执行过滤器链。 Spring框架中如何基于AOP实现事务管理 事务管理，是一个切面。在aop环节中，其他环节都一样，事务管理就是由Spring提供的advice，既是TransactionInterceptor，它一样的会在过滤器链中被执行到，这个TransactionInterceptor 过滤器类是通过解析 tx:advice 自定义标签得到的。 描述SpringMvc的整个访问或者调用流程 发起请求到前端控制器（DispatcherServlet) 前端控制器请求HandlerMapping查找Handler（可以根据xml配置，注解查找），处理器映射器 HandlerMapping 向前端控制器返回Handler 前端控制器调用处理器适配器去执行 Handler 处理器适配器去执行Handler Handler 执行完成给适配器返回 ModelAndView，处理器适配器向前端控制器返回 ModelAndView(ModelAndView 是 springmvc 框架的一个底层对象，包括 model 和 view) 前端控制器请求视图解析器去进行视图解析（根据逻辑视图名解析成真正的视图（jsp）），视图解析器向前端控制器返回 View 前端控制器进行视图渲染（视图渲染将模型数据填充到request域） 前端控制器向用户响应结果 ","link":"http://blog.801314.top/post/mianshi-java-jichu/"},{"title":"《大宅门》里白景琦的两封遗书","content":"七爷的第一封遗书 &quot;我，白景琦，生于光绪六年，自幼顽劣，不服管教，闹私塾，打兄弟，毁老师，无恶不作。长大成人更肆无忌惮，与仇家女私订终身，杀德国兵，交日本朋友，终被慈母大人赶出家门；从此闯荡江湖，独创家业。&quot; &quot;一泡屎骗了两千银子，收了沿河二十八坊，独创'泷胶'、'保生'、'九宝'、'七秀'三十二张秘方，济世救民，兴家旺族；为九红，我坐过督军的大牢，为槐花，坐过民国的监狱，为香秀，得罪过全家老少，越不叫我干什么，我偏要干什么！除了我妈，我没向谁低过头，没向谁弯过腰！&quot; &quot;如今，日本鬼子打到了咱们家门口，逼死了三老太爷，我立誓，宁死不当亡国奴！我死以后，本族老少如有与日本鬼子通同一气者，人人可骂之！我死以后，如有与日本鬼子通同一气者，人人可诛之！我死以后，……如有与日本鬼子通同一气者，照着我这口刀说话！&quot; 立遗嘱人，白景琦！ 七爷的第二封遗书 “我,白景琦，生于光绪六年，今年86了。一只烤鸭是吃不动了，酒还能喝半坛子。神龟虽寿，犹有竟时。为昭示子孙后代立此遗嘱： 景琦一生，无愧于祖先无愧于家人。自日寇侵华以来，屡遭迫害，身陷囹圄，保住了秘方。为抗日尽了微薄之力，惟气节二字，不曾丝毫动摇。 光复之日，又遭诬陷，九死一生，虽百折而不屈。回首来路，刀光剑影，血迹斑斑，幸得解放，迎来盛世。 景琦未敢稍稍怠慢。举合营之首，献秘方于先，赴总理之茶话会，参政协之学习班，亦步亦趋，不甘落同仁之后。无奈子孙不孝，为夺财产，父子相争，夫妻反目，兄弟结仇，姊妹相残，景琦已无回天之力，更不忍见后代子孙专以争夺财产为能事，不思进取。 自今日起，全部国宝珍玩尽献与故宫博物院。自今日起，放弃全部股息，以期子孙自食其力，报效国家。我死以后，如有子孙念及先祖之苦心，烧一陌纸钱，焚一柱清香。就说你已自立，你已成才，景琦死亦瞑目。 立遗嘱人:白景琦 ","link":"http://blog.801314.top/post/dazhaimen/"},{"title":"《闻香识女人》经典台词","content":"1、 如今我走到人生十字路口，我知道哪条路是对的，毫无例外，我就知道，但我从不走，为什么？因为他妈的太苦了！ 2、问题不是哪条路是对的，问题是，你敢不敢走？人即使身残，也因保持灵魂的完整，因为灵魂没有假肢。 3、 我想有个女人拥住我，我埋在她的秀发里闻香，而第二天醒来，她还在我身边。 4、我知道哪条路都能通向正道，但是我从不尝试，为什么？因为，走正道太难。 5、 探戈里无所谓错步的，不像人生。 6、有时决定了要走，却总是徘徊留恋。有时决定留下，眼神却总望着远方的山水。没关系，唱首歌，走走停停地看看风景。一条路始终有个尽头。 7、如果一个人是坏人，并不是因为他本性有多恶，只是因为他的生命中积累了太多的的坏。是的，世界上没有坏人，只有在痛苦中的人。 8、世界就是如此，东窗事发的时候有人走，有人留。 9、逃避责任的倾向谁都有，但正因如此，世界才呼唤“正直”和“勇气”。 10、如果你跳错了也没关系，接着跳下去。 11、舞跳错了还可以继续，但生活不一样。 12、没有什么比精神残废更可怕，因为没有义肢可以装。一个女人的坚强精神，比她的外在更可贵，因为即便她独自一人，也能光芒四射。 13、如果一个人是坏人，并不是因为他本性有多恶，只是因为他的生命中积累了太多坏的东西。世界上没有坏人，只有在痛苦中的人。 14、没有什么比残缺的灵魂更可怕，而且那是任何东西都无法填补的。 ","link":"http://blog.801314.top/post/lesslesswen-xiang-shi-nu-ren-greatergreater-jing-dian-tai-ci/"},{"title":"资深架构师成长路线 -- 分布式方案及团队协作工具","content":"1、分布式事务解决方案 事务与锁 标准分布式事务 两阶段提交 BASE理论与柔性事务 TCC方案 补偿性方案 异步确保型与最大努力型 2、单点登录方案 单点登录的问题背景 页面跨域问题 Session跨域共享方案 Session 的扩展 3、分布式任务调度方案 Quartz调度的用法 Elastic-Job示例 分布式调度的疑难点 Quartz集群定制化分布式调度 4、Maven 安装与配置 使用入门 坐标和依赖 聚合与继承 生命周期与插件 仓库及版本管理 私服-Nexus 手写Maven插件实战 5、Jenkins Jenkins远程测试 Jenkins持续部署 Jenkins自动部署 Jenkins分布式构建 Jenkins管理 Jenkinis安装 6、git 与svn对比 基本运作流程 Git常用操作及问题处理 ","link":"http://blog.801314.top/post/jiagoushi-gongju/"},{"title":"资深架构师成长路线 -- 分布式扩展到微服务架构","content":"1、从RPC开始 服务注册与发布 动态代理 序列化与反射 手写RPC框架实战 2、DUBBO 10分钟学会Dubbo使用 项目之间的依赖划分实战 传统项目拆解分布式实战 Dubbo api 扩展实战 Dubbo 源码深度解读 Dubbo 面试题指南 3、Spriing Boot Spring Boot 快速入门 核心组件分析 性能优化 jta+atomikos分布式事务 SpringBoot核心源码解读 手写SpringBoot实战 SpringBoot面试汇总 4、Spring Cloud Netflix Zuul路由网关详解及源码探析 Ribbon客户端负载均衡原理与算法详解 Feign 声明式服务调用方式实现 Hystrix服务熔断及服务降级实战 Eureka注册中心构件分析 Config配置服务中心与svn，git快速集成 BUS消息总线技术 Sleuth调用链路跟踪 Stream 消息驱动的微服务 SpringCloud 面试题目汇总 5、Spring Cloud Alibaba Nacos Nacos概述 Nacos-Discovery服务发现 配置中心Nacos-Config Sky Walking 链路跟踪概述 客户端/服务端实战 Assembly Plugin Sentinel （限流） Sentinel 熔断器特性 Sentinel 回退机制 Feigb集成Sentinel Sentinel-Dashboard Seata（分布式事务） 角色中的角色 Seata Server Seata请求逻辑 实战分布式事务 6、docker 5分钟搞定Docker安装与使用 Docker的基本操作 Docker File快速进阶 Docker网络与存储那些事 DockerCompose高阶用法 微服务与Docker集成实现动态扩容实战 7、kubernets Kubernetes简介及安装配置 Kubernetes核心原理 Kubernetes集群管理方案实战 8、Service Mesh 10分钟快速入门与介绍 核心组件解析 如何利用Helm部署Istio 快速解析Istio的常用功能 Mixer适配器的应用 http流量管理实战 Istio的安全加固实战 ","link":"http://blog.801314.top/post/jiagoushi-fenbushi/"},{"title":"资深架构师成长路线 -- 高效存储让项目性能起飞","content":"1、Redis 5分钟搞定Linux下Redis安装 String，List，Hash，Set，Zset类型使用场景 时间轴、队列应用场景设计实战 购物车开发与设计实战 Redis与Lua模拟抢红包实战 网站投票设计与开发实战 Lua+Redis联合开发指南 Redis慢操作优化 Redis哨兵机制及底层机制分析 10分钟搭建Redis高可用集群实战 动态扩容，缩减集群节点实战 Redis 常见面试题汇总 2、缓存解决方案实战 15分钟掌握项目中SpringCache的用法 缓存的一致性策略（跟下及失效处理机制） 缓存雪崩解决方案 缓存穿透方案 3、mongoDB Mongodb使用场景分析 20分钟完整增删改查 MongoDB开发时你应该注意的事项 安全设置及存储引擎分析指南 性能调优与索引实战 复制架构解析实战 MongoDB分区实战 4、MySql高可用 Mysql主从复制、读写分离高可用方案实战 Mysql+keepalived实现双主高可用方案实战 Mysql实现分库分表高性能解决方案实战 5、Mycat Mycat简介及用途 基于Mycat实现Mysql读写分离实战 基于Mycat实现数据库切分实战 全局表、ER表、分片机制分析 6、Sharding-Sphere Sharding-JDBC 引擎原理与数据分片剖析 读写分离 编排治理 数据脱敏 Sharding-Proxy 7、FastDFS 文件存储实战 文件同步实战 文件查询实战 分布式部署实战 ","link":"http://blog.801314.top/post/jiagoushi-gaoxiao/"},{"title":"资深架构师成长路线 -- 性能直线提升架构技术","content":"1、分布式架构思维 大型互联网架构严谨过程 架构师应具备的分布式知识 主流分布式架构设计详解 2、Zookeeper 5分钟搞定Zookeeper安装及指令解析 原始客户端、zkclient、curotor快速开发实战 zookeeper应用实战 配置中心 命名服务 集群选举实战 分布式锁实战 zookeeper底层协议解读 2p, 3p cap base paxos zab zookeeper 面试资料整理 3、nginx 5分钟将你的项目实现nginx分流 nginx安装及基本使用 nginx进程模型及配置详解 location规则及rewrite解析 动静分离实战 反向代理实战 跨域配置实战 缓存配置及gzip配置实战 https安全认证实战 LVS高可用实战 nginx那些面试题汇总 4、消息中间件概述 消息中间件和RPC的区别 消息中间件使用场景介绍 ActiveMQ，RabbitMQ，RocketMQ，Kafka对比 消息中间件的编年史 5、ActiveMQ 3分钟快速安装ActiveMQ JMS规范解读 原生ActiveMQ的API编程 ActiveMQ高级特性和用法 限时订单实战 用户注册的异步处理实战 企业高可用集群部署实战 6、RabbitMQ Linux下安装与配置 消息发布与消费权衡 消息的拒绝怎么解决 控制队列与消息属性 与Spring集成完成应用结偶实战 集群化与镜像队列实战 RabbitMQ常见面试题汇总 7、RocketMQ RocketMQ快速安装与配置 消息发送与消费流程解读 RocketMQ消息存储，消息过滤及事务消息 RocketMQ高可用实战 整合Spring完成用户注册的异步处理实战 整合Spring完成限时订单实战 RocketMQ面试题汇集 8、Kafka Kafka快速安装部署 开启Kafka的集群模式 Kafka的生产者和消费者 Kafka高级特性解读 Kafka处理请求的内部机制剖析 整合Spring完成削峰填谷实战 Kafka面试题汇集 9、elastic ELK ElasticSearch ES原理 ES搜素 索引&amp;映射 分布式CRUD 索引管理 分片 搜索优化 logstash 安装和运行 配置 kibana 安装和运行 配置 ELK常见面试题汇集 ","link":"http://blog.801314.top/post/jiagoushi3/"},{"title":"资深架构师成长路线 -- 设计思想解读开源框架","content":"1、六大原则 单一职责原则 开闭原则 里氏替换原则 依赖倒置原则 接口隔离原则 迪米特法则 2、结构型模式 桥接模式 适配器模式 装饰器模式 代理模式 组合模式 3、创建型模式 建造者模式 单例模式 抽象工厂模式 工厂方法模式 静态工厂模式 4、行为型模式 模版方法模式 策略模式 观察者模式 责任链模式 命令模式 访问者模式 5、Spring 5源码解读 5分钟快速理解Spring核心流程 熟练掌握Spring工作常用注解及陷阱 后置处理器源码解读 BeanFactoryPostProcessor BeanDefinetionRegistry IOC容器源码解读 BeanFactory初始化 各类BeanPostProcessors注册执行 MessageSoource资源国际化初始化 事件派发器、监听器初始化 Bean准备创建工作 完成容器创建 AOP源码解读 AOP核心类的注册及执行时机分析 AOP代理创建原理及源码剖析 AOP核心功能之拦截器链解读 方法压栈及链式调用原则解读 声明式事务源码解读 Spring源码面试题汇总 6、SpringMVC 框架源码解读 Servlet3.0 ServletContainerInitializer容器初始化 ServletRegistration 注册 FilterRegistration过滤器 ServletContext 性能实战 基于Servlet3.0 异步 Callable异步 DeferredResult异步 手写SpringMVC实战 7、Mybatis框架源码解读 5分钟掌握MyBatis的配置使用 动态SQL、缓存及关联查询深入解析 10分钟掌握MyBatis与Spring的集成实战 Mybatis插件开发及源码分析实战 分页插件使用与源码分析 多级关联实战 手写MyBatis框架实战 Mybatis常见面试题汇集 ","link":"http://blog.801314.top/post/jiagoushi1/"},{"title":"资深架构师成长路线 -- 架构师筑基必备技能","content":"1、并发编程进阶 线程共享和写作文 CPU核心数，线程数，时间片轮转机制解读 synchronized，volatile，ThreadLocal 如何实现线程共享 wait，notify/nofityAll，join 方法如何实现线程间协作 并发工具类实战 Fork/Join 分而治之原理及实战 CountDownLatch，CyclicBarrier应用场景和实战 Callable，Future和Future Task源码解读及应用实战 Semaphore，Exchange应用场景和实战 站在巨人肩上操作CAS CAS的原理 CAS带来的ABA问题 原子操作类的正确使用实战 阿里面试常问的显式锁和AQS 深入剖析显示锁Lock底层实现机制 AbstractQueuedSynchronizer实现及源码分析 AQS使用方式及其设计模式 ReentrantLock的底层源码及应用实战 并发容器源码解析及应用实战 ConcurrentHashMap 源码解读及应用实战 ConncurrentHashMap 在JDK1.7，JDK1.8版本对比 ConcurrentSkipListMap，ConcurrentLinkedQueue 源码解读 仅会用线程池是不够的 线程池底层实现分析 手写线程池实战 Executor框架解读实战 架构师应该知道的并发安全解决方案 性能优化实战 深入分析JMM（Java 内存模型） 并发任务执行框架解读 30分钟搞定应用性能优化实战 并发编程面试题目汇集 2、JVM性能深度调优 15种方式编写高效优雅Java程序实战 Java内存区域深入剖析 程序计数器，栈，堆及方法区等 JDK1.6，JDK1.7, JDK1.8 内存区域的变化 站在线程角度来看堆和栈 虚拟机中的对象深度剖析 堆参数设置和内存溢出实战 垃圾回收的内存分配策略 对象存活及强，弱等各种引用辨析 快速解读GC算法之标记-清除、复制及标记-整理算法 正确姿势解读GC日志 快速搞定MAT工具，解读DUMP文件 抽丝剥茧解决内存泄露和内存溢出 你必须知道的JVM执行子系统 类加载机制原理剖析 JVM栈帧及方法调用详解 基于栈等字节码解释执行引擎解读 JVM的类加载机制及执行引擎原理 JVM性能优化实战 常用等性能优化手段分析 GC调用实战 JVM调优实战 JVM 面试锦囊妙计 3、网络编程与高效IO http/tcp/udp网络协议原理透析 原始JDK网络编程 BIO编程 NIO 编程 Netty应用快速入门 Netty粘包/半包文问题解决实战 Netty进阶和实战 服务器推送技术实战 WebSocket通信实战 手写通信框架实战 Netty源码深入分析 Netty常被问到的那些面试题汇集 4、深入Tomcat底层 10分钟熟悉你常用却不知道的Tomcat体系架构 你必须得知道的Tomcat容器及运行机制 Tomcat类加载机制分析 Tomcat 核心组件源码解读 Tomcat高级进阶 手写嵌入式Tomcat实战 Tomcat 优化实战 Tomcat面试题整理 5、Mysql深度优化 Mysql存储引擎选型及注意事项 解读Mysql的共享锁及排他锁 Mysql事务及隔离性级别 30 分钟深入展望执行计划 解读Btree与B+ tree索引 Sql慢查询配置及分析 Sql优化策略及实战 Mysql面试题汇总 6、架构基础必备Linux Linux 安装指南 Linux 基础明亮 用户与用户组系列操作 文件与权限系列操作 架构师应该掌握的shell脚本基础 ","link":"http://blog.801314.top/post/jiagoushi/"},{"title":"《教父》中老教父 维托·唐·柯里昂的经典名言","content":"分享一些《教父》里很精辟地诠释了社会人生的台词： 1、但凡男女之间的那点“意思”，常常是从“不好意思”开始，到“真没意思”结束。 2、不要憎恨你的敌人，那会影响你的判断力。 3、在这个世界上，常常出现这样的情况：最微不足道的人，如果他时刻留意的话，总有机会向那些不可一世的人报仇雪恨。 4、不要轻易说出你的理想，不给别人嘲笑你的机会。 5、除了朋友低估你的优点，世上最大的天然优势就是敌人高估你的缺陷。 6、你有花时间和你的家人在一起吗? 我当然有. 很好!不照顾家人的男人,根本算不上是个男人。 7、永远不要动怒，绝不要威胁，要讲道理。 8、最好的威胁是不采取行动，一旦采取行动却没收到效果，人们就不再怕威胁了。 9、我用了一生的时间，就学会了两个字：小心。 10、伟大的人不是生下来就伟大的，而是在成长过程中显示其伟大的。 11、在一秒钟内看到本质的人和花半辈子也看不清一件事本质的人,自然是不一样的命运。 12、你做出了这个决定，这是你的代价。 13、没有边界的心软，只会让对方得寸进尺；毫无原则的仁慈，只会让对方为所欲为。 14、要宽恕，要遗忘。生命本来就充满了不幸。 15、迈克?柯里昂破天荒地第一次悟出一个道理，为什么像他父亲那样的人，甘愿当盗窃犯和谋杀犯而不愿意当合法社会的守法公民？贫穷，恐惧，屈辱，这些东西太可怕了，对任何一个有骨气的人。 16、社会上常常会有突如其来的侮辱，那是必须忍受的。 17、巨大财富的背后，都隐藏着罪恶。 18、人可以不断犯错，但绝不能犯要命的错。 19、离你的朋友近些，但离你的敌人要更近，这样你才能更了解他。 20、人之常情，这世上最难处的就是人了。得罪一个人有很多原因，拂了对方一片好心，也是一种得罪。 21、不要让外人知道家族内部的不同意见。 22、第一个帮你敌人说话的兄弟是叛徒。 23、如果一个人很慷慨，那他就必须把自己的慷慨表现得充满感情。 24、永远不要让别人知道你的真实想法。 25、不要说不可能，没有什么不可能。 26、痛苦不像死亡那样无可挽回。 27、和许多天才商人一样，他知道自由竞争是浪费的，垄断才有效率。所以，他的目标就是追求这有效的垄断。 28、以猛虎之形，以蔷薇之声。 29、我伤了感情了，但是我这个人并不把自己的友谊强加于那些不重视友谊的人——那些认为我无足轻重的人。 ","link":"http://blog.801314.top/post/lesslessjiao-fu-greatergreater-zhong-lao-jiao-fu-wei-tuo-tang-ke-li-ang-de-jing-dian-ming-yan/"},{"title":"世间所有的相遇，都是久别重逢","content":"欢迎你来到我的博客❤️ 很喜欢《一代宗师》电影里的一句台词： 世间所有的相遇，都是久别重逢 能来到这里，说明你我有缘💐 如果通过我的文章，你喜欢和我结交的话，欢迎联系我（联系方式在主页--&gt; 关于我中） 没事故事没有酒😂 只有闲谈与白话🤣 ","link":"http://blog.801314.top/post/meet/"},{"title":"First ","content":"整了很久终于搞定了，之后可以作为个人博客发布内容了😀 ","link":"http://blog.801314.top/post/first/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"http://blog.801314.top/post/hello-gridea/"}]}